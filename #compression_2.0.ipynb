{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Compression happening\n","\n","## distilbert = 60%\n","\n","## T5 = 60%\n","\n","## T5 base 83.00%\n","\n","## funnel_transformer smallbase 68%\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## T5 base 83.00%"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-07-03T09:20:08.772652Z","iopub.status.busy":"2024-07-03T09:20:08.771957Z","iopub.status.idle":"2024-07-03T09:21:17.953614Z","shell.execute_reply":"2024-07-03T09:21:17.952531Z","shell.execute_reply.started":"2024-07-03T09:20:08.772605Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/azureuser/pavan/train/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["Replaced layer: encoder.block.0.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.0.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.0.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.0.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.0.layer.1.DenseReluDense.wi\n","Replaced layer: encoder.block.0.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.1.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.1.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.1.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.1.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.1.layer.1.DenseReluDense.wi\n","Replaced layer: encoder.block.1.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.2.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.2.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.2.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.2.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.2.layer.1.DenseReluDense.wi\n","Replaced layer: encoder.block.2.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.3.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.3.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.3.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.3.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.3.layer.1.DenseReluDense.wi\n","Replaced layer: encoder.block.3.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.4.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.4.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.4.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.4.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.4.layer.1.DenseReluDense.wi\n","Replaced layer: encoder.block.4.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.5.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.5.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.5.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.5.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.5.layer.1.DenseReluDense.wi\n","Replaced layer: encoder.block.5.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.6.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.6.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.6.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.6.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.6.layer.1.DenseReluDense.wi\n","Replaced layer: encoder.block.6.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.7.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.7.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.7.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.7.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.7.layer.1.DenseReluDense.wi\n","Replaced layer: encoder.block.7.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.8.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.8.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.8.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.8.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.8.layer.1.DenseReluDense.wi\n","Replaced layer: encoder.block.8.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.9.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.9.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.9.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.9.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.9.layer.1.DenseReluDense.wi\n","Replaced layer: encoder.block.9.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.10.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.10.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.10.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.10.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.10.layer.1.DenseReluDense.wi\n","Replaced layer: encoder.block.10.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.11.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.11.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.11.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.11.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.11.layer.1.DenseReluDense.wi\n","Replaced layer: encoder.block.11.layer.1.DenseReluDense.wo\n","Replaced layer: decoder.block.0.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.0.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.0.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.0.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.0.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.0.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.0.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.0.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.0.layer.2.DenseReluDense.wi\n","Replaced layer: decoder.block.0.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.1.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.1.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.1.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.1.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.1.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.1.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.1.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.1.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.1.layer.2.DenseReluDense.wi\n","Replaced layer: decoder.block.1.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.2.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.2.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.2.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.2.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.2.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.2.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.2.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.2.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.2.layer.2.DenseReluDense.wi\n","Replaced layer: decoder.block.2.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.3.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.3.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.3.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.3.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.3.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.3.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.3.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.3.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.3.layer.2.DenseReluDense.wi\n","Replaced layer: decoder.block.3.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.4.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.4.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.4.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.4.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.4.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.4.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.4.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.4.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.4.layer.2.DenseReluDense.wi\n","Replaced layer: decoder.block.4.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.5.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.5.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.5.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.5.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.5.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.5.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.5.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.5.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.5.layer.2.DenseReluDense.wi\n","Replaced layer: decoder.block.5.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.6.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.6.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.6.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.6.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.6.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.6.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.6.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.6.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.6.layer.2.DenseReluDense.wi\n","Replaced layer: decoder.block.6.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.7.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.7.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.7.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.7.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.7.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.7.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.7.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.7.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.7.layer.2.DenseReluDense.wi\n","Replaced layer: decoder.block.7.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.8.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.8.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.8.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.8.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.8.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.8.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.8.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.8.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.8.layer.2.DenseReluDense.wi\n","Replaced layer: decoder.block.8.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.9.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.9.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.9.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.9.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.9.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.9.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.9.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.9.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.9.layer.2.DenseReluDense.wi\n","Replaced layer: decoder.block.9.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.10.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.10.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.10.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.10.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.10.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.10.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.10.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.10.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.10.layer.2.DenseReluDense.wi\n","Replaced layer: decoder.block.10.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.11.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.11.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.11.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.11.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.11.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.11.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.11.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.11.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.11.layer.2.DenseReluDense.wi\n","Replaced layer: decoder.block.11.layer.2.DenseReluDense.wo\n","Original model size (parameters): 222903552\n","Compressed model size (parameters): 37895424\n","Compression rate: 83.00%\n","Model saved to directory: compressed_model\n"]}],"source":["import torch\n","import torch.nn as nn\n","from transformers import AutoTokenizer, AutoModel\n","from torch.nn import functional as F\n","\n","# Specify the model name and compression rank\n","MODEL_NAME = 'google-t5/t5-base'  # Replace with your desired model name\n","COMPRESSION_RANK = 32 # Adjust this for more or less aggressive compression\n","\n","# Define LowRankLayer class for low-rank decomposition\n","class LowRankLayer(nn.Module):\n","    \"\"\"Given a linear layer, find low rank decomposition.\"\"\"\n","    def __init__(self, rank, full_rank_layer):\n","        super().__init__()\n","        self.rank = rank\n","\n","        # Perform SVD on the full-rank layer's weight matrix\n","        U, S, Vh = torch.linalg.svd(full_rank_layer.weight.float())\n","        S_diag = torch.diag(S)\n","        self.U = nn.Parameter(U[:, :self.rank].contiguous())\n","        self.S = nn.Parameter(S_diag[:self.rank, :self.rank].contiguous())\n","        self.Vh = nn.Parameter(Vh[:self.rank, :].contiguous())\n","\n","        # Handle the bias term if it exists\n","        if full_rank_layer.bias is not None:\n","            self.bias = nn.Parameter(full_rank_layer.bias.float().contiguous())\n","        else:\n","            self.bias = None\n","\n","    def forward(self, x):\n","        aprox_weight_matrix = self.U @ self.S @ self.Vh\n","        output = F.linear(x, aprox_weight_matrix, self.bias)\n","        return output\n","\n","# Function to replace linear layers with LowRankLayer\n","def replace_with_low_rank(model, rank):\n","    for name, module in model.named_modules():\n","        if isinstance(module, nn.Linear):\n","            # Create a LowRankLayer to replace the full-rank linear layer\n","            low_rank_layer = LowRankLayer(rank, module)\n","            parent_name, child_name = name.rsplit('.', 1)\n","            parent_module = model.get_submodule(parent_name)\n","            setattr(parent_module, child_name, low_rank_layer)\n","            print(f\"Replaced layer: {name}\")\n","    return model\n","\n","# Function to calculate the total number of parameters in the model\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","# Load the tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModel.from_pretrained(MODEL_NAME)\n","\n","# Get initial size\n","original_size = count_parameters(model)\n","\n","# Replace linear layers with low-rank approximations\n","model = replace_with_low_rank(model, COMPRESSION_RANK)\n","\n","# Get final size\n","compressed_size = count_parameters(model)\n","\n","# Print sizes and compression rate\n","print(f\"Original model size (parameters): {original_size}\")\n","print(f\"Compressed model size (parameters): {compressed_size}\")\n","print(f\"Compression rate: {(original_size - compressed_size) / original_size:.2%}\")\n","\n","# Save the tokenizer and model to the directory\n","model_dir = \"compressed_model\"\n","tokenizer.save_pretrained(model_dir)\n","model.save_pretrained(model_dir)\n","\n","print(f\"Model saved to directory: {model_dir}\")\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting sentencepiece\n","  Using cached sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n","Using cached sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","Installing collected packages: sentencepiece\n","Successfully installed sentencepiece-0.2.0\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install sentencepiece\n"]},{"cell_type":"markdown","metadata":{},"source":["## Better script with storing models only in temp, and more print statements"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/azureuser/pavan/train/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"]},{"name":"stdout","output_type":"stream","text":["Replaced layer: encoder.block.0.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.0.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.0.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.0.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.0.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.0.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.0.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.1.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.1.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.1.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.1.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.1.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.1.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.1.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.2.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.2.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.2.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.2.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.2.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.2.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.2.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.3.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.3.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.3.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.3.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.3.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.3.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.3.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.4.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.4.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.4.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.4.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.4.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.4.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.4.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.5.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.5.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.5.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.5.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.5.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.5.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.5.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.6.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.6.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.6.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.6.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.6.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.6.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.6.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.7.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.7.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.7.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.7.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.7.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.7.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.7.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.8.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.8.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.8.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.8.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.8.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.8.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.8.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.9.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.9.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.9.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.9.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.9.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.9.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.9.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.10.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.10.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.10.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.10.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.10.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.10.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.10.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.11.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.11.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.11.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.11.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.11.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.11.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.11.layer.1.DenseReluDense.wo\n","Replaced layer: decoder.block.0.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.0.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.0.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.0.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.0.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.0.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.0.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.0.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.0.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.0.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.0.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.1.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.1.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.1.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.1.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.1.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.1.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.1.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.1.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.1.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.1.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.1.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.2.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.2.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.2.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.2.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.2.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.2.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.2.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.2.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.2.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.2.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.2.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.3.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.3.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.3.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.3.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.3.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.3.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.3.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.3.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.3.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.3.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.3.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.4.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.4.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.4.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.4.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.4.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.4.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.4.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.4.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.4.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.4.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.4.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.5.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.5.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.5.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.5.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.5.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.5.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.5.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.5.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.5.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.5.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.5.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.6.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.6.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.6.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.6.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.6.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.6.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.6.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.6.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.6.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.6.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.6.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.7.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.7.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.7.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.7.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.7.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.7.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.7.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.7.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.7.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.7.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.7.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.8.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.8.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.8.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.8.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.8.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.8.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.8.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.8.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.8.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.8.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.8.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.9.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.9.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.9.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.9.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.9.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.9.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.9.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.9.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.9.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.9.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.9.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.10.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.10.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.10.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.10.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.10.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.10.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.10.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.10.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.10.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.10.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.10.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.11.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.11.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.11.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.11.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.11.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.11.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.11.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.11.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.11.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.11.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.11.layer.2.DenseReluDense.wo\n","Original model size (parameters): 222903552\n","Compressed model size (parameters): 38509824\n","Parameter compression rate: 82.72%\n","Original model size (bytes): 850.43 MB\n","Compressed model size (bytes): 147.16 MB\n","File size compression rate: 82.70%\n","Compressed model saved to directory: compressed_model\n"]}],"source":["import torch\n","import torch.nn as nn\n","from transformers import AutoTokenizer, AutoModel\n","from torch.nn import functional as F\n","import tempfile\n","import os\n","\n","# Specify the model name and compression rank\n","MODEL_NAME = 'google/t5-v1_1-base'  # Replace with your desired model name\n","COMPRESSION_RANK = 32  # Adjust this for more or less aggressive compression\n","\n","# Define LowRankLayer class for low-rank decomposition\n","class LowRankLayer(nn.Module):\n","    \"\"\"Given a linear layer, find low rank decomposition.\"\"\"\n","    def __init__(self, rank, full_rank_layer):\n","        super().__init__()\n","        self.rank = rank\n","\n","        # Perform SVD on the full-rank layer's weight matrix\n","        U, S, Vh = torch.linalg.svd(full_rank_layer.weight.float())\n","        S_diag = torch.diag(S)\n","        self.U = nn.Parameter(U[:, :self.rank].contiguous())\n","        self.S = nn.Parameter(S_diag[:self.rank, :self.rank].contiguous())\n","        self.Vh = nn.Parameter(Vh[:self.rank, :].contiguous())\n","\n","        # Handle the bias term if it exists\n","        if full_rank_layer.bias is not None:\n","            self.bias = nn.Parameter(full_rank_layer.bias.float().contiguous())\n","        else:\n","            self.bias = None\n","\n","    def forward(self, x):\n","        aprox_weight_matrix = self.U @ self.S @ self.Vh\n","        output = F.linear(x, aprox_weight_matrix, self.bias)\n","        return output\n","\n","# Function to replace linear layers with LowRankLayer\n","def replace_with_low_rank(model, rank):\n","    for name, module in model.named_modules():\n","        if isinstance(module, nn.Linear):\n","            # Create a LowRankLayer to replace the full-rank linear layer\n","            low_rank_layer = LowRankLayer(rank, module)\n","            parent_name, child_name = name.rsplit('.', 1)\n","            parent_module = model.get_submodule(parent_name)\n","            setattr(parent_module, child_name, low_rank_layer)\n","            print(f\"Replaced layer: {name}\")\n","    return model\n","\n","# Function to calculate the total number of parameters in the model\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","# Function to get the size of a model saved to a temporary file\n","def get_model_size_in_bytes(model):\n","    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n","        torch.save(model.state_dict(), tmp_file.name)\n","        tmp_file.seek(0, os.SEEK_END)\n","        size = tmp_file.tell()\n","    os.remove(tmp_file.name)  # Delete the temporary file immediately after getting its size\n","    return size\n","\n","# Load the tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModel.from_pretrained(MODEL_NAME)\n","\n","# Get initial parameter count and file size\n","original_size_params = count_parameters(model)\n","original_size_bytes = get_model_size_in_bytes(model)\n","\n","# Replace linear layers with low-rank approximations\n","model = replace_with_low_rank(model, COMPRESSION_RANK)\n","\n","# Get final parameter count and file size\n","compressed_size_params = count_parameters(model)\n","compressed_size_bytes = get_model_size_in_bytes(model)\n","\n","# Print sizes and compression rates\n","print(f\"Original model size (parameters): {original_size_params}\")\n","print(f\"Compressed model size (parameters): {compressed_size_params}\")\n","print(f\"Parameter compression rate: {(original_size_params - compressed_size_params) / original_size_params:.2%}\")\n","\n","print(f\"Original model size (bytes): {original_size_bytes / (1024 ** 2):.2f} MB\")\n","print(f\"Compressed model size (bytes): {compressed_size_bytes / (1024 ** 2):.2f} MB\")\n","print(f\"File size compression rate: {(original_size_bytes - compressed_size_bytes) / original_size_bytes:.2%}\")\n","\n","# Save the tokenizer and compressed model to the directory\n","model_dir = \"compressed_model\"\n","tokenizer.save_pretrained(model_dir)\n","model.save_pretrained(model_dir)\n","\n","print(f\"Compressed model saved to directory: {model_dir}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Similar to SVDLLM"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Replaced layer: encoder.block.0.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.0.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.0.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.0.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.0.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.0.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.0.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.1.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.1.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.1.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.1.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.1.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.1.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.1.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.2.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.2.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.2.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.2.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.2.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.2.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.2.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.3.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.3.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.3.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.3.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.3.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.3.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.3.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.4.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.4.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.4.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.4.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.4.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.4.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.4.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.5.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.5.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.5.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.5.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.5.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.5.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.5.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.6.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.6.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.6.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.6.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.6.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.6.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.6.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.7.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.7.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.7.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.7.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.7.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.7.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.7.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.8.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.8.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.8.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.8.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.8.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.8.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.8.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.9.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.9.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.9.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.9.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.9.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.9.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.9.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.10.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.10.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.10.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.10.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.10.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.10.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.10.layer.1.DenseReluDense.wo\n","Replaced layer: encoder.block.11.layer.0.SelfAttention.q\n","Replaced layer: encoder.block.11.layer.0.SelfAttention.k\n","Replaced layer: encoder.block.11.layer.0.SelfAttention.v\n","Replaced layer: encoder.block.11.layer.0.SelfAttention.o\n","Replaced layer: encoder.block.11.layer.1.DenseReluDense.wi_0\n","Replaced layer: encoder.block.11.layer.1.DenseReluDense.wi_1\n","Replaced layer: encoder.block.11.layer.1.DenseReluDense.wo\n","Replaced layer: decoder.block.0.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.0.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.0.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.0.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.0.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.0.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.0.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.0.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.0.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.0.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.0.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.1.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.1.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.1.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.1.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.1.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.1.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.1.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.1.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.1.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.1.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.1.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.2.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.2.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.2.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.2.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.2.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.2.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.2.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.2.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.2.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.2.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.2.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.3.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.3.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.3.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.3.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.3.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.3.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.3.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.3.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.3.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.3.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.3.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.4.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.4.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.4.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.4.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.4.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.4.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.4.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.4.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.4.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.4.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.4.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.5.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.5.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.5.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.5.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.5.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.5.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.5.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.5.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.5.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.5.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.5.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.6.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.6.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.6.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.6.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.6.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.6.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.6.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.6.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.6.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.6.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.6.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.7.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.7.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.7.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.7.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.7.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.7.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.7.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.7.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.7.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.7.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.7.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.8.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.8.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.8.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.8.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.8.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.8.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.8.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.8.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.8.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.8.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.8.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.9.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.9.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.9.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.9.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.9.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.9.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.9.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.9.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.9.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.9.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.9.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.10.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.10.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.10.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.10.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.10.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.10.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.10.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.10.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.10.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.10.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.10.layer.2.DenseReluDense.wo\n","Replaced layer: decoder.block.11.layer.0.SelfAttention.q\n","Replaced layer: decoder.block.11.layer.0.SelfAttention.k\n","Replaced layer: decoder.block.11.layer.0.SelfAttention.v\n","Replaced layer: decoder.block.11.layer.0.SelfAttention.o\n","Replaced layer: decoder.block.11.layer.1.EncDecAttention.q\n","Replaced layer: decoder.block.11.layer.1.EncDecAttention.k\n","Replaced layer: decoder.block.11.layer.1.EncDecAttention.v\n","Replaced layer: decoder.block.11.layer.1.EncDecAttention.o\n","Replaced layer: decoder.block.11.layer.2.DenseReluDense.wi_0\n","Replaced layer: decoder.block.11.layer.2.DenseReluDense.wi_1\n","Replaced layer: decoder.block.11.layer.2.DenseReluDense.wo\n","Replaced layer: lm_head\n","Start obtaining the whitening matrix...\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/25 [00:00<?, ?it/s]\n"]},{"ename":"AttributeError","evalue":"'LowRankLayer' object has no attribute 'weight'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 210\u001b[0m\n\u001b[1;32m    208\u001b[0m calib_dataset \u001b[38;5;241m=\u001b[39m DummyDataset()\n\u001b[1;32m    209\u001b[0m calib_loader \u001b[38;5;241m=\u001b[39m DataLoader(calib_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 210\u001b[0m profiling_mat \u001b[38;5;241m=\u001b[39m \u001b[43mprofile_and_whiten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalib_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m whitening(MODEL_NAME, model, profiling_mat, COMPRESSION_RANK \u001b[38;5;241m/\u001b[39m original_size_params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# Get final parameter count and file size\u001b[39;00m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[8], line 119\u001b[0m, in \u001b[0;36mprofile_and_whiten\u001b[0;34m(model, calib_loader, dev)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(calib_loader):\n\u001b[1;32m    118\u001b[0m     batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(dev) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 119\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_modules():\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module, nn\u001b[38;5;241m.\u001b[39mLinear):\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1702\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1699\u001b[0m \u001b[38;5;66;03m# Encode if needed (training, first prediction pass)\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1701\u001b[0m     \u001b[38;5;66;03m# Convert encoder inputs in embeddings if needed\u001b[39;00m\n\u001b[0;32m-> 1702\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1703\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n\u001b[1;32m   1712\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1713\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1714\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1715\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1716\u001b[0m     )\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1106\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1091\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1092\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1093\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1103\u001b[0m         output_attentions,\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1106\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:746\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    743\u001b[0m     attention_outputs \u001b[38;5;241m=\u001b[39m attention_outputs \u001b[38;5;241m+\u001b[39m cross_attention_outputs[\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m    745\u001b[0m \u001b[38;5;66;03m# Apply Feed Forward layer\u001b[39;00m\n\u001b[0;32m--> 746\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hidden_states\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16:\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:335\u001b[0m, in \u001b[0;36mT5LayerFF.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m    334\u001b[0m     forwarded_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 335\u001b[0m     forwarded_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDenseReluDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforwarded_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(forwarded_states)\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:312\u001b[0m, in \u001b[0;36mT5DenseGatedActDense.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    306\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# To make 8bit quantization work for google/flan-t5-xxl, self.wo is kept in float32.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# See https://github.com/huggingface/transformers/issues/20287\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# we also make sure the weights are not in `int8` in case users will force `_keep_in_fp32_modules` to be `None``\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m, torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m hidden_states\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwo\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwo\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mint8\n\u001b[1;32m    315\u001b[0m ):\n\u001b[1;32m    316\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwo\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    318\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwo(hidden_states)\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/torch/nn/modules/module.py:1709\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1709\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: 'LowRankLayer' object has no attribute 'weight'"]}],"source":["import os\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","import tempfile\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader, Dataset\n","\n","# Specify the model name and compression rank\n","MODEL_NAME = 'google/t5-v1_1-base'\n","COMPRESSION_RANK = 32\n","\n","# Dummy dataset for calibration (replace with your actual dataset)\n","class DummyDataset(Dataset):\n","    def __init__(self, size=100, seq_len=512, vocab_size=32128):\n","        self.size = size\n","        self.seq_len = seq_len\n","        self.vocab_size = vocab_size\n","\n","    def __len__(self):\n","        return self.size\n","\n","    def __getitem__(self, idx):\n","        input_ids = torch.randint(0, self.vocab_size, (self.seq_len,))\n","        attention_mask = torch.ones(self.seq_len)\n","        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n","\n","# Define LowRankLayer class for low-rank decomposition\n","class LowRankLayer(nn.Module):\n","    \"\"\"Given a linear layer, find low rank decomposition.\"\"\"\n","    def __init__(self, rank, full_rank_layer):\n","        super().__init__()\n","        self.rank = rank\n","\n","        # Perform SVD on the full-rank layer's weight matrix\n","        U, S, Vh = torch.linalg.svd(full_rank_layer.weight.float())\n","        S_diag = torch.diag(S)\n","        self.U = nn.Parameter(U[:, :self.rank].contiguous())\n","        self.S = nn.Parameter(S_diag[:self.rank, :self.rank].contiguous())\n","        self.Vh = nn.Parameter(Vh[:self.rank, :].contiguous())\n","\n","        # Handle the bias term if it exists\n","        if full_rank_layer.bias is not None:\n","            self.bias = nn.Parameter(full_rank_layer.bias.float().contiguous())\n","        else:\n","            self.bias = None\n","\n","    def forward(self, x):\n","        aprox_weight_matrix = self.U @ self.S @ self.Vh\n","        output = F.linear(x, aprox_weight_matrix, self.bias)\n","        return output\n","\n","# Function to replace linear layers with LowRankLayer\n","def replace_with_low_rank(model, rank):\n","    for name, module in model.named_modules():\n","        if isinstance(module, nn.Linear):\n","            # Create a LowRankLayer to replace the full-rank linear layer\n","            low_rank_layer = LowRankLayer(rank, module)\n","            if '.' in name:\n","                parent_name, child_name = name.rsplit('.', 1)\n","                parent_module = model.get_submodule(parent_name)\n","            else:\n","                parent_module = model\n","                child_name = name\n","            setattr(parent_module, child_name, low_rank_layer)\n","            print(f\"Replaced layer: {name}\")\n","    return model\n","\n","# Function to calculate the total number of parameters in the model\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","# Function to get the size of a model saved to a temporary file\n","def get_model_size_in_bytes(model):\n","    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n","        torch.save(model.state_dict(), tmp_file.name)\n","        tmp_file.seek(0, os.SEEK_END)\n","        size = tmp_file.tell()\n","    os.remove(tmp_file.name)  # Delete the temporary file immediately after getting its size\n","    return size\n","\n","# Function to find layers in a module\n","def find_layers(module, layers=None):\n","    if layers is None:\n","        layers = {}\n","    for name, sub_module in module.named_children():\n","        if isinstance(sub_module, nn.Linear):\n","            layers[name] = sub_module\n","        else:\n","            find_layers(sub_module, layers)\n","    return layers\n","\n","# Function to perform profiling and whitening\n","@torch.no_grad()\n","def profile_and_whiten(model, calib_loader, dev):\n","    layers = model.encoder.block + model.decoder.block\n","    model = model.to(dev)\n","    print(\"Start obtaining the whitening matrix...\")\n","\n","    def hook(module, input, output):\n","        inp = input[0].detach().float()\n","        if inp.dim() == 2:   # For some layers\n","            inp = inp.unsqueeze(0)\n","        adds = torch.matmul(inp.transpose(1, 2), inp)\n","        adds_sum = torch.sum(adds, dim=0)\n","        if hasattr(module, 'raw_scaling_diag_matrix'):\n","            module.raw_scaling_diag_matrix += adds_sum\n","        del inp, adds, adds_sum\n","        torch.cuda.empty_cache()\n","\n","    for name, module in model.named_modules():\n","        if isinstance(module, nn.Linear):\n","            module.raw_scaling_diag_matrix = 0\n","            module.register_forward_hook(hook)\n","\n","    for batch in tqdm(calib_loader):\n","        batch = {k: v.to(dev) for k, v in batch.items()}\n","        model(**batch)\n","\n","    for name, module in model.named_modules():\n","        if isinstance(module, nn.Linear):\n","            module._forward_hooks.clear()\n","    torch.cuda.empty_cache()\n","\n","    model = model.cpu()\n","    profiling_mat = {}\n","    print(\"Start Cholesky Decomposition...\")\n","\n","    for layer in layers:\n","        subset = find_layers(layer)\n","        for name in subset:\n","            if not hasattr(subset[name], 'raw_scaling_diag_matrix'):\n","                continue\n","            raw_scaling_diag_matrix = subset[name].raw_scaling_diag_matrix.double().to(dev)\n","            try:\n","                scaling_diag_matrix = torch.linalg.cholesky(raw_scaling_diag_matrix)\n","            except Exception as e:\n","                print(\"Warning: eigen scaling_diag_matrix is not positive!\")\n","                eigenvalues = torch.linalg.eigvalsh(raw_scaling_diag_matrix)\n","                raw_scaling_diag_matrix += (-eigenvalues[0] + 1e-6) * torch.eye(raw_scaling_diag_matrix.shape[0]).to(dev)\n","                scaling_diag_matrix = torch.linalg.cholesky(raw_scaling_diag_matrix)\n","            profiling_mat[name] = scaling_diag_matrix.cpu()\n","            del scaling_diag_matrix, raw_scaling_diag_matrix, subset[name].raw_scaling_diag_matrix\n","            torch.cuda.empty_cache()\n","    return profiling_mat\n","\n","# Function to perform whitening and low-rank decomposition\n","@torch.no_grad()\n","def whitening(model_name, model, profiling_mat, ratio, dev):\n","    model.eval()\n","    layers = model.encoder.block + model.decoder.block\n","    print(\"Start SVD decomposition after whitening...\")\n","\n","    for layer in layers:\n","        subset = find_layers(layer)\n","        for name in subset:\n","            if not hasattr(subset[name], 'weight'):\n","                continue\n","            W = subset[name].weight.data.float().to(dev)\n","            dtype = W.dtype\n","            scaling_diag_matrix = profiling_mat.get(name, None)\n","            if scaling_diag_matrix is None:\n","                continue\n","            scaling_diag_matrix = scaling_diag_matrix.to(dev)\n","            try:\n","                scaling_matrix_inv = torch.linalg.inv(scaling_diag_matrix)\n","            except Exception as e:\n","                print(\"Warning: scaling_diag_matrix is not full rank!\")\n","                scaling_diag_matrix += 1e-6 * torch.eye(scaling_diag_matrix.shape[0]).to(dev)\n","                scaling_matrix_inv = torch.linalg.inv(scaling_diag_matrix)\n","            W_scale = torch.matmul(W, scaling_diag_matrix)\n","            U, S, VT = torch.linalg.svd(W_scale, full_matrices=False)\n","            num_s_after_trunc = int(W.shape[0] * W.shape[1] * ratio / (W.shape[0] + W.shape[1]))\n","            truc_s = S[:num_s_after_trunc]\n","            truc_u = U[:, :num_s_after_trunc]\n","            truc_v = torch.matmul(VT[:num_s_after_trunc, :], scaling_matrix_inv)\n","            truc_sigma = torch.diag(truc_s)\n","            sqrtSigma = torch.sqrt(truc_sigma)\n","            svd_u = torch.matmul(truc_u, sqrtSigma).cpu().to(dtype)\n","            svd_v = torch.matmul(sqrtSigma, truc_v).cpu().to(dtype)\n","            low_rank_layer = LowRankLayer(svd_u.size(1), subset[name])\n","            low_rank_layer.U = nn.Parameter(svd_u)\n","            low_rank_layer.S = nn.Parameter(truc_sigma)\n","            low_rank_layer.Vh = nn.Parameter(svd_v)\n","            if '.' in name:\n","                parent_name, child_name = name.rsplit('.', 1)\n","                parent_module = model.get_submodule(parent_name)\n","            else:\n","                parent_module = model\n","                child_name = name\n","            setattr(parent_module, child_name, low_rank_layer)\n","            del W, W_scale, scaling_matrix_inv, scaling_diag_matrix, U, S, VT, truc_s, truc_u, truc_v, sqrtSigma\n","            torch.cuda.empty_cache()\n","\n","# Load the tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n","\n","# Get initial parameter count and file size\n","original_size_params = count_parameters(model)\n","original_size_bytes = get_model_size_in_bytes(model)\n","\n","# Replace linear layers with low-rank approximations\n","model = replace_with_low_rank(model, COMPRESSION_RANK)\n","\n","# Profiling and Whitening\n","calib_dataset = DummyDataset()\n","calib_loader = DataLoader(calib_dataset, batch_size=4, shuffle=True)\n","profiling_mat = profile_and_whiten(model, calib_loader, 'cuda')\n","whitening(MODEL_NAME, model, profiling_mat, COMPRESSION_RANK / original_size_params, 'cuda')\n","\n","# Get final parameter count and file size\n","compressed_size_params = count_parameters(model)\n","compressed_size_bytes = get_model_size_in_bytes(model)\n","\n","# Print sizes and compression rates\n","print(f\"Original model size (parameters): {original_size_params}\")\n","print(f\"Compressed model size (parameters): {compressed_size_params}\")\n","print(f\"Parameter compression rate: {(original_size_params - compressed_size_params) / original_size_params:.2%}\")\n","\n","print(f\"Original model size (bytes): {original_size_bytes / (1024 ** 2):.2f} MB\")\n","print(f\"Compressed model size (bytes): {compressed_size_bytes / (1024 ** 2):.2f} MB\")\n","print(f\"File size compression rate: {(original_size_bytes - compressed_size_bytes) / original_size_bytes:.2%}\")\n","\n","# Save the tokenizer and compressed model to the directory\n","model_dir = \"compressed_model\"\n","tokenizer.save_pretrained(model_dir)\n","model.save_pretrained(model_dir)\n","\n","print(f\"Compressed model saved to directory: {model_dir}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## LLama3 Trial"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/azureuser/pavan/train/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stderr","output_type":"stream","text":["Downloading shards: 100%|| 4/4 [00:55<00:00, 13.75s/it]\n","Loading checkpoint shards: 100%|| 4/4 [00:03<00:00,  1.05it/s]\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"data":{"text/plain":["[{'generated_text': 'Hey how are you doing today? Im really excited to be here, Im going to be talking about the top 5 mistakes that people make when it comes to their finances and how to avoid them. So, lets get started. Number one, not having a budget. This is one of the biggest mistakes that people make, because without a budget you dont know where your money is going and youre more likely to overspend. So, the first thing you need to do is sit down and create a budget for yourself. This will help you track your spending and make sure that youre staying on track. Number two, not saving enough for retirement. This is another big mistake that people make, because they dont realize how much they need to save for retirement until its too late. So, make sure that youre saving at least 10% of your income every month for retirement. Number three, not having an emergency fund. This is something that everyone should have, because you never know when an emergency is going to happen and youll need to have money set aside for it. So, make sure that you have at least three months worth of expenses saved up in case of an emergency. Number four, not taking advantage of tax breaks. There are a lot of tax breaks out there that you can take advantage of, but you need to know about them in order to do so. So, make sure that youre doing your research and taking advantage of all the tax breaks that youre eligible for. Number five, not having a will or estate plan. This is something that everyone should have, because it will ensure that your assets are distributed according to your wishes in case of your death. So, make sure that you have a will or estate plan in place so that your loved ones are taken care of after youre gone. So, those are the top 5 mistakes that people make when it comes to their finances and how to avoid them. If you want to learn more about how to improve your finances, be sure to check out our website or give us a call. We would be happy to help you get started on the right track. Thanks for watching and Ill see you next time!'}]"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import transformers\n","import torch\n","\n","model_id = \"meta-llama/Meta-Llama-3-8B\"\n","\n","pipeline = transformers.pipeline(\"text-generation\", model=model_id, model_kwargs={\"torch_dtype\": torch.bfloat16}, device_map=\"auto\")\n","pipeline(\"Hey how are you doing today?\")\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/azureuser/pavan/train/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","/home/azureuser/pavan/train/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/home/azureuser/pavan/train/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","Some weights of LlamaForCausalLM were not initialized from the model checkpoint at pavan01729/Compressed_LLama3_8b and are newly initialized: ['layers.13.self_attn.k_proj.weight', 'layers.21.self_attn.o_proj.weight', 'layers.9.mlp.up_proj.weight', 'layers.21.self_attn.q_proj.weight', 'layers.23.mlp.up_proj.weight', 'layers.0.self_attn.q_proj.weight', 'layers.4.self_attn.q_proj.weight', 'layers.8.self_attn.o_proj.weight', 'layers.11.mlp.gate_proj.weight', 'layers.11.self_attn.q_proj.weight', 'layers.26.mlp.up_proj.weight', 'layers.27.self_attn.v_proj.weight', 'layers.25.mlp.down_proj.weight', 'layers.31.mlp.up_proj.weight', 'layers.5.self_attn.k_proj.weight', 'layers.23.mlp.gate_proj.weight', 'layers.17.mlp.up_proj.weight', 'layers.15.mlp.up_proj.weight', 'layers.16.mlp.gate_proj.weight', 'layers.19.mlp.down_proj.weight', 'layers.18.self_attn.o_proj.weight', 'layers.17.self_attn.q_proj.weight', 'layers.6.mlp.up_proj.weight', 'layers.15.mlp.gate_proj.weight', 'layers.8.mlp.gate_proj.weight', 'layers.28.mlp.down_proj.weight', 'layers.23.self_attn.k_proj.weight', 'layers.28.self_attn.v_proj.weight', 'layers.17.mlp.gate_proj.weight', 'layers.4.mlp.down_proj.weight', 'layers.5.self_attn.q_proj.weight', 'layers.16.mlp.down_proj.weight', 'layers.5.mlp.up_proj.weight', 'layers.12.self_attn.v_proj.weight', 'layers.13.mlp.down_proj.weight', 'layers.19.mlp.up_proj.weight', 'layers.22.self_attn.v_proj.weight', 'layers.24.self_attn.q_proj.weight', 'layers.18.self_attn.k_proj.weight', 'layers.31.self_attn.k_proj.weight', 'layers.15.mlp.down_proj.weight', 'layers.5.self_attn.v_proj.weight', 'layers.30.mlp.down_proj.weight', 'layers.20.self_attn.o_proj.weight', 'layers.24.self_attn.v_proj.weight', 'layers.26.self_attn.k_proj.weight', 'layers.19.self_attn.q_proj.weight', 'layers.24.self_attn.k_proj.weight', 'layers.0.mlp.up_proj.weight', 'layers.8.self_attn.k_proj.weight', 'layers.24.mlp.up_proj.weight', 'layers.6.self_attn.o_proj.weight', 'layers.25.mlp.gate_proj.weight', 'layers.31.self_attn.o_proj.weight', 'layers.17.self_attn.v_proj.weight', 'layers.18.self_attn.v_proj.weight', 'layers.6.self_attn.v_proj.weight', 'layers.4.self_attn.k_proj.weight', 'layers.12.mlp.up_proj.weight', 'layers.29.self_attn.o_proj.weight', 'layers.9.self_attn.v_proj.weight', 'layers.0.mlp.down_proj.weight', 'layers.2.mlp.up_proj.weight', 'layers.10.self_attn.q_proj.weight', 'layers.7.mlp.gate_proj.weight', 'layers.1.mlp.down_proj.weight', 'lm_head.weight', 'layers.27.self_attn.k_proj.weight', 'layers.15.self_attn.q_proj.weight', 'layers.18.mlp.up_proj.weight', 'layers.14.mlp.up_proj.weight', 'layers.23.self_attn.o_proj.weight', 'layers.10.self_attn.k_proj.weight', 'layers.22.self_attn.k_proj.weight', 'layers.3.self_attn.o_proj.weight', 'layers.18.mlp.gate_proj.weight', 'layers.16.mlp.up_proj.weight', 'layers.21.self_attn.k_proj.weight', 'layers.22.self_attn.q_proj.weight', 'layers.26.self_attn.v_proj.weight', 'layers.2.mlp.gate_proj.weight', 'layers.17.mlp.down_proj.weight', 'layers.10.self_attn.v_proj.weight', 'layers.13.self_attn.o_proj.weight', 'layers.1.self_attn.v_proj.weight', 'layers.20.self_attn.k_proj.weight', 'layers.1.self_attn.o_proj.weight', 'layers.24.mlp.down_proj.weight', 'layers.20.mlp.up_proj.weight', 'layers.3.self_attn.v_proj.weight', 'layers.3.self_attn.k_proj.weight', 'layers.12.self_attn.o_proj.weight', 'layers.24.self_attn.o_proj.weight', 'layers.12.mlp.gate_proj.weight', 'layers.16.self_attn.q_proj.weight', 'layers.29.mlp.down_proj.weight', 'layers.28.mlp.gate_proj.weight', 'layers.14.mlp.gate_proj.weight', 'layers.25.self_attn.o_proj.weight', 'layers.8.mlp.up_proj.weight', 'layers.11.mlp.up_proj.weight', 'layers.4.self_attn.v_proj.weight', 'layers.11.self_attn.o_proj.weight', 'layers.7.self_attn.v_proj.weight', 'layers.21.self_attn.v_proj.weight', 'layers.14.self_attn.q_proj.weight', 'layers.31.self_attn.v_proj.weight', 'layers.27.self_attn.o_proj.weight', 'layers.29.self_attn.v_proj.weight', 'layers.30.self_attn.q_proj.weight', 'layers.14.self_attn.v_proj.weight', 'layers.19.mlp.gate_proj.weight', 'layers.21.mlp.up_proj.weight', 'layers.23.mlp.down_proj.weight', 'layers.18.mlp.down_proj.weight', 'layers.22.mlp.gate_proj.weight', 'layers.30.self_attn.v_proj.weight', 'layers.19.self_attn.o_proj.weight', 'layers.9.mlp.gate_proj.weight', 'layers.7.self_attn.k_proj.weight', 'layers.31.self_attn.q_proj.weight', 'layers.30.mlp.up_proj.weight', 'layers.2.self_attn.o_proj.weight', 'layers.17.self_attn.o_proj.weight', 'layers.9.mlp.down_proj.weight', 'layers.13.mlp.up_proj.weight', 'layers.13.mlp.gate_proj.weight', 'layers.27.self_attn.q_proj.weight', 'layers.7.self_attn.o_proj.weight', 'layers.24.mlp.gate_proj.weight', 'layers.11.self_attn.v_proj.weight', 'layers.22.mlp.down_proj.weight', 'layers.20.self_attn.v_proj.weight', 'layers.30.self_attn.k_proj.weight', 'layers.27.mlp.gate_proj.weight', 'layers.17.self_attn.k_proj.weight', 'layers.5.self_attn.o_proj.weight', 'layers.29.self_attn.k_proj.weight', 'layers.10.mlp.gate_proj.weight', 'layers.8.self_attn.q_proj.weight', 'layers.27.mlp.up_proj.weight', 'layers.6.self_attn.k_proj.weight', 'layers.13.self_attn.v_proj.weight', 'layers.4.self_attn.o_proj.weight', 'layers.20.mlp.down_proj.weight', 'layers.10.mlp.down_proj.weight', 'layers.9.self_attn.q_proj.weight', 'layers.30.mlp.gate_proj.weight', 'layers.9.self_attn.k_proj.weight', 'layers.15.self_attn.k_proj.weight', 'layers.15.self_attn.o_proj.weight', 'layers.3.self_attn.q_proj.weight', 'layers.21.mlp.down_proj.weight', 'layers.30.self_attn.o_proj.weight', 'layers.2.self_attn.q_proj.weight', 'layers.5.mlp.down_proj.weight', 'layers.16.self_attn.k_proj.weight', 'layers.26.self_attn.o_proj.weight', 'layers.26.mlp.down_proj.weight', 'layers.1.self_attn.k_proj.weight', 'layers.26.mlp.gate_proj.weight', 'layers.8.self_attn.v_proj.weight', 'layers.4.mlp.gate_proj.weight', 'layers.28.self_attn.q_proj.weight', 'layers.16.self_attn.o_proj.weight', 'layers.23.self_attn.q_proj.weight', 'layers.9.self_attn.o_proj.weight', 'layers.13.self_attn.q_proj.weight', 'layers.10.self_attn.o_proj.weight', 'layers.2.self_attn.v_proj.weight', 'layers.26.self_attn.q_proj.weight', 'layers.12.self_attn.k_proj.weight', 'layers.20.self_attn.q_proj.weight', 'layers.14.self_attn.o_proj.weight', 'layers.23.self_attn.v_proj.weight', 'layers.10.mlp.up_proj.weight', 'layers.22.mlp.up_proj.weight', 'layers.22.self_attn.o_proj.weight', 'layers.7.self_attn.q_proj.weight', 'layers.1.self_attn.q_proj.weight', 'layers.14.self_attn.k_proj.weight', 'layers.0.self_attn.k_proj.weight', 'layers.8.mlp.down_proj.weight', 'layers.7.mlp.down_proj.weight', 'layers.6.mlp.down_proj.weight', 'layers.25.self_attn.v_proj.weight', 'layers.6.mlp.gate_proj.weight', 'layers.18.self_attn.q_proj.weight', 'layers.14.mlp.down_proj.weight', 'layers.12.self_attn.q_proj.weight', 'layers.11.self_attn.k_proj.weight', 'layers.2.mlp.down_proj.weight', 'layers.2.self_attn.k_proj.weight', 'layers.5.mlp.gate_proj.weight', 'layers.19.self_attn.v_proj.weight', 'layers.0.mlp.gate_proj.weight', 'layers.20.mlp.gate_proj.weight', 'layers.28.self_attn.k_proj.weight', 'layers.29.mlp.gate_proj.weight', 'layers.1.mlp.up_proj.weight', 'layers.28.self_attn.o_proj.weight', 'layers.11.mlp.down_proj.weight', 'layers.25.self_attn.q_proj.weight', 'layers.16.self_attn.v_proj.weight', 'layers.7.mlp.up_proj.weight', 'layers.25.self_attn.k_proj.weight', 'layers.25.mlp.up_proj.weight', 'layers.3.mlp.down_proj.weight', 'layers.31.mlp.down_proj.weight', 'layers.15.self_attn.v_proj.weight', 'layers.27.mlp.down_proj.weight', 'layers.21.mlp.gate_proj.weight', 'layers.6.self_attn.q_proj.weight', 'layers.0.self_attn.v_proj.weight', 'layers.31.mlp.gate_proj.weight', 'layers.29.self_attn.q_proj.weight', 'layers.12.mlp.down_proj.weight', 'layers.28.mlp.up_proj.weight', 'layers.3.mlp.gate_proj.weight', 'layers.0.self_attn.o_proj.weight', 'layers.19.self_attn.k_proj.weight', 'layers.1.mlp.gate_proj.weight', 'layers.3.mlp.up_proj.weight', 'layers.4.mlp.up_proj.weight', 'layers.29.mlp.up_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some parameters are on the meta device device because they were offloaded to the cpu.\n","/home/azureuser/pavan/train/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n","pip install xformers.\n","/home/azureuser/pavan/train/lib/python3.10/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"ename":"RuntimeError","evalue":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpavan01729/Compressed_LLama3_8b\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mpipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel_id, model_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mbfloat16}, device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHey how are you doing today?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:200\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    160\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03m    Complete the prompt(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/transformers/pipelines/base.py:1122\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1115\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1116\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         )\n\u001b[1;32m   1120\u001b[0m     )\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/transformers/pipelines/base.py:1129\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1128\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1129\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1130\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/transformers/pipelines/base.py:1028\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1027\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1028\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:261\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m         generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prefix_length\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# BS x SL\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/transformers/generation/utils.py:1538\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1532\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1533\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_return_sequences has to be 1 when doing greedy search, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1534\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1535\u001b[0m         )\n\u001b[1;32m   1537\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1546\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_contrastive_search_gen_mode:\n\u001b[1;32m   1552\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mnum_return_sequences \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/transformers/generation/utils.py:2362\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2359\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2361\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2362\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2363\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2365\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2366\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2367\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2370\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:806\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    803\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    805\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 806\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:693\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    685\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    686\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[1;32m    687\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    691\u001b[0m     )\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 693\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:405\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m    hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03m    past_key_value (`Tuple(torch.FloatTensor)`, *optional*): cached past key and value projection states\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    403\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 405\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m    408\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    409\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    410\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    414\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    415\u001b[0m )\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m~/pavan/train/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:86\u001b[0m, in \u001b[0;36mLlamaRMSNorm.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m     85\u001b[0m     input_dtype \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m---> 86\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     variance \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     88\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(variance \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariance_epsilon)\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"]}],"source":["import transformers\n","import torch\n","\n","model_id = \"pavan01729/Compressed_LLama3_8b\"\n","\n","pipeline = transformers.pipeline(\"text-generation\", model=model_id, model_kwargs={\"torch_dtype\": torch.bfloat16}, device_map=\"auto\")\n","pipeline(\"Hey how are you doing today?\")\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc90e145893b4ddab33e631fdf2b56cd","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Replaced layer: layers.0.self_attn.q_proj\n","Replaced layer: layers.0.self_attn.k_proj\n","Replaced layer: layers.0.self_attn.v_proj\n","Replaced layer: layers.0.self_attn.o_proj\n","Replaced layer: layers.0.mlp.gate_proj\n","Replaced layer: layers.0.mlp.up_proj\n","Replaced layer: layers.0.mlp.down_proj\n","Replaced layer: layers.1.self_attn.q_proj\n","Replaced layer: layers.1.self_attn.k_proj\n","Replaced layer: layers.1.self_attn.v_proj\n","Replaced layer: layers.1.self_attn.o_proj\n","Replaced layer: layers.1.mlp.gate_proj\n","Replaced layer: layers.1.mlp.up_proj\n","Replaced layer: layers.1.mlp.down_proj\n","Replaced layer: layers.2.self_attn.q_proj\n","Replaced layer: layers.2.self_attn.k_proj\n","Replaced layer: layers.2.self_attn.v_proj\n","Replaced layer: layers.2.self_attn.o_proj\n","Replaced layer: layers.2.mlp.gate_proj\n","Replaced layer: layers.2.mlp.up_proj\n","Replaced layer: layers.2.mlp.down_proj\n","Replaced layer: layers.3.self_attn.q_proj\n","Replaced layer: layers.3.self_attn.k_proj\n","Replaced layer: layers.3.self_attn.v_proj\n","Replaced layer: layers.3.self_attn.o_proj\n","Replaced layer: layers.3.mlp.gate_proj\n","Replaced layer: layers.3.mlp.up_proj\n","Replaced layer: layers.3.mlp.down_proj\n","Replaced layer: layers.4.self_attn.q_proj\n","Replaced layer: layers.4.self_attn.k_proj\n","Replaced layer: layers.4.self_attn.v_proj\n","Replaced layer: layers.4.self_attn.o_proj\n","Replaced layer: layers.4.mlp.gate_proj\n","Replaced layer: layers.4.mlp.up_proj\n","Replaced layer: layers.4.mlp.down_proj\n","Replaced layer: layers.5.self_attn.q_proj\n","Replaced layer: layers.5.self_attn.k_proj\n","Replaced layer: layers.5.self_attn.v_proj\n","Replaced layer: layers.5.self_attn.o_proj\n","Replaced layer: layers.5.mlp.gate_proj\n","Replaced layer: layers.5.mlp.up_proj\n","Replaced layer: layers.5.mlp.down_proj\n","Replaced layer: layers.6.self_attn.q_proj\n","Replaced layer: layers.6.self_attn.k_proj\n","Replaced layer: layers.6.self_attn.v_proj\n","Replaced layer: layers.6.self_attn.o_proj\n","Replaced layer: layers.6.mlp.gate_proj\n","Replaced layer: layers.6.mlp.up_proj\n","Replaced layer: layers.6.mlp.down_proj\n","Replaced layer: layers.7.self_attn.q_proj\n","Replaced layer: layers.7.self_attn.k_proj\n","Replaced layer: layers.7.self_attn.v_proj\n","Replaced layer: layers.7.self_attn.o_proj\n","Replaced layer: layers.7.mlp.gate_proj\n","Replaced layer: layers.7.mlp.up_proj\n","Replaced layer: layers.7.mlp.down_proj\n","Replaced layer: layers.8.self_attn.q_proj\n","Replaced layer: layers.8.self_attn.k_proj\n","Replaced layer: layers.8.self_attn.v_proj\n","Replaced layer: layers.8.self_attn.o_proj\n","Replaced layer: layers.8.mlp.gate_proj\n","Replaced layer: layers.8.mlp.up_proj\n","Replaced layer: layers.8.mlp.down_proj\n","Replaced layer: layers.9.self_attn.q_proj\n","Replaced layer: layers.9.self_attn.k_proj\n","Replaced layer: layers.9.self_attn.v_proj\n","Replaced layer: layers.9.self_attn.o_proj\n","Replaced layer: layers.9.mlp.gate_proj\n","Replaced layer: layers.9.mlp.up_proj\n","Replaced layer: layers.9.mlp.down_proj\n","Replaced layer: layers.10.self_attn.q_proj\n","Replaced layer: layers.10.self_attn.k_proj\n","Replaced layer: layers.10.self_attn.v_proj\n","Replaced layer: layers.10.self_attn.o_proj\n","Replaced layer: layers.10.mlp.gate_proj\n","Replaced layer: layers.10.mlp.up_proj\n","Replaced layer: layers.10.mlp.down_proj\n","Replaced layer: layers.11.self_attn.q_proj\n","Replaced layer: layers.11.self_attn.k_proj\n","Replaced layer: layers.11.self_attn.v_proj\n","Replaced layer: layers.11.self_attn.o_proj\n","Replaced layer: layers.11.mlp.gate_proj\n","Replaced layer: layers.11.mlp.up_proj\n","Replaced layer: layers.11.mlp.down_proj\n","Replaced layer: layers.12.self_attn.q_proj\n","Replaced layer: layers.12.self_attn.k_proj\n","Replaced layer: layers.12.self_attn.v_proj\n","Replaced layer: layers.12.self_attn.o_proj\n","Replaced layer: layers.12.mlp.gate_proj\n","Replaced layer: layers.12.mlp.up_proj\n","Replaced layer: layers.12.mlp.down_proj\n","Replaced layer: layers.13.self_attn.q_proj\n","Replaced layer: layers.13.self_attn.k_proj\n","Replaced layer: layers.13.self_attn.v_proj\n","Replaced layer: layers.13.self_attn.o_proj\n","Replaced layer: layers.13.mlp.gate_proj\n","Replaced layer: layers.13.mlp.up_proj\n","Replaced layer: layers.13.mlp.down_proj\n","Replaced layer: layers.14.self_attn.q_proj\n","Replaced layer: layers.14.self_attn.k_proj\n","Replaced layer: layers.14.self_attn.v_proj\n","Replaced layer: layers.14.self_attn.o_proj\n","Replaced layer: layers.14.mlp.gate_proj\n","Replaced layer: layers.14.mlp.up_proj\n","Replaced layer: layers.14.mlp.down_proj\n","Replaced layer: layers.15.self_attn.q_proj\n","Replaced layer: layers.15.self_attn.k_proj\n","Replaced layer: layers.15.self_attn.v_proj\n","Replaced layer: layers.15.self_attn.o_proj\n","Replaced layer: layers.15.mlp.gate_proj\n","Replaced layer: layers.15.mlp.up_proj\n","Replaced layer: layers.15.mlp.down_proj\n","Replaced layer: layers.16.self_attn.q_proj\n","Replaced layer: layers.16.self_attn.k_proj\n","Replaced layer: layers.16.self_attn.v_proj\n","Replaced layer: layers.16.self_attn.o_proj\n","Replaced layer: layers.16.mlp.gate_proj\n","Replaced layer: layers.16.mlp.up_proj\n","Replaced layer: layers.16.mlp.down_proj\n","Replaced layer: layers.17.self_attn.q_proj\n","Replaced layer: layers.17.self_attn.k_proj\n","Replaced layer: layers.17.self_attn.v_proj\n","Replaced layer: layers.17.self_attn.o_proj\n","Replaced layer: layers.17.mlp.gate_proj\n","Replaced layer: layers.17.mlp.up_proj\n","Replaced layer: layers.17.mlp.down_proj\n","Replaced layer: layers.18.self_attn.q_proj\n","Replaced layer: layers.18.self_attn.k_proj\n","Replaced layer: layers.18.self_attn.v_proj\n","Replaced layer: layers.18.self_attn.o_proj\n","Replaced layer: layers.18.mlp.gate_proj\n","Replaced layer: layers.18.mlp.up_proj\n","Replaced layer: layers.18.mlp.down_proj\n","Replaced layer: layers.19.self_attn.q_proj\n","Replaced layer: layers.19.self_attn.k_proj\n","Replaced layer: layers.19.self_attn.v_proj\n","Replaced layer: layers.19.self_attn.o_proj\n","Replaced layer: layers.19.mlp.gate_proj\n","Replaced layer: layers.19.mlp.up_proj\n","Replaced layer: layers.19.mlp.down_proj\n","Replaced layer: layers.20.self_attn.q_proj\n","Replaced layer: layers.20.self_attn.k_proj\n","Replaced layer: layers.20.self_attn.v_proj\n","Replaced layer: layers.20.self_attn.o_proj\n","Replaced layer: layers.20.mlp.gate_proj\n","Replaced layer: layers.20.mlp.up_proj\n","Replaced layer: layers.20.mlp.down_proj\n","Replaced layer: layers.21.self_attn.q_proj\n","Replaced layer: layers.21.self_attn.k_proj\n","Replaced layer: layers.21.self_attn.v_proj\n","Replaced layer: layers.21.self_attn.o_proj\n","Replaced layer: layers.21.mlp.gate_proj\n","Replaced layer: layers.21.mlp.up_proj\n","Replaced layer: layers.21.mlp.down_proj\n","Replaced layer: layers.22.self_attn.q_proj\n","Replaced layer: layers.22.self_attn.k_proj\n","Replaced layer: layers.22.self_attn.v_proj\n","Replaced layer: layers.22.self_attn.o_proj\n","Replaced layer: layers.22.mlp.gate_proj\n","Replaced layer: layers.22.mlp.up_proj\n","Replaced layer: layers.22.mlp.down_proj\n","Replaced layer: layers.23.self_attn.q_proj\n","Replaced layer: layers.23.self_attn.k_proj\n","Replaced layer: layers.23.self_attn.v_proj\n","Replaced layer: layers.23.self_attn.o_proj\n","Replaced layer: layers.23.mlp.gate_proj\n","Replaced layer: layers.23.mlp.up_proj\n","Replaced layer: layers.23.mlp.down_proj\n","Replaced layer: layers.24.self_attn.q_proj\n","Replaced layer: layers.24.self_attn.k_proj\n","Replaced layer: layers.24.self_attn.v_proj\n","Replaced layer: layers.24.self_attn.o_proj\n","Replaced layer: layers.24.mlp.gate_proj\n","Replaced layer: layers.24.mlp.up_proj\n","Replaced layer: layers.24.mlp.down_proj\n","Replaced layer: layers.25.self_attn.q_proj\n","Replaced layer: layers.25.self_attn.k_proj\n","Replaced layer: layers.25.self_attn.v_proj\n","Replaced layer: layers.25.self_attn.o_proj\n","Replaced layer: layers.25.mlp.gate_proj\n","Replaced layer: layers.25.mlp.up_proj\n","Replaced layer: layers.25.mlp.down_proj\n","Replaced layer: layers.26.self_attn.q_proj\n","Replaced layer: layers.26.self_attn.k_proj\n","Replaced layer: layers.26.self_attn.v_proj\n","Replaced layer: layers.26.self_attn.o_proj\n","Replaced layer: layers.26.mlp.gate_proj\n","Replaced layer: layers.26.mlp.up_proj\n","Replaced layer: layers.26.mlp.down_proj\n","Replaced layer: layers.27.self_attn.q_proj\n","Replaced layer: layers.27.self_attn.k_proj\n","Replaced layer: layers.27.self_attn.v_proj\n","Replaced layer: layers.27.self_attn.o_proj\n","Replaced layer: layers.27.mlp.gate_proj\n","Replaced layer: layers.27.mlp.up_proj\n","Replaced layer: layers.27.mlp.down_proj\n","Replaced layer: layers.28.self_attn.q_proj\n","Replaced layer: layers.28.self_attn.k_proj\n","Replaced layer: layers.28.self_attn.v_proj\n","Replaced layer: layers.28.self_attn.o_proj\n","Replaced layer: layers.28.mlp.gate_proj\n","Replaced layer: layers.28.mlp.up_proj\n","Replaced layer: layers.28.mlp.down_proj\n","Replaced layer: layers.29.self_attn.q_proj\n","Replaced layer: layers.29.self_attn.k_proj\n","Replaced layer: layers.29.self_attn.v_proj\n","Replaced layer: layers.29.self_attn.o_proj\n","Replaced layer: layers.29.mlp.gate_proj\n","Replaced layer: layers.29.mlp.up_proj\n","Replaced layer: layers.29.mlp.down_proj\n","Replaced layer: layers.30.self_attn.q_proj\n","Replaced layer: layers.30.self_attn.k_proj\n","Replaced layer: layers.30.self_attn.v_proj\n","Replaced layer: layers.30.self_attn.o_proj\n","Replaced layer: layers.30.mlp.gate_proj\n","Replaced layer: layers.30.mlp.up_proj\n","Replaced layer: layers.30.mlp.down_proj\n","Replaced layer: layers.31.self_attn.q_proj\n","Replaced layer: layers.31.self_attn.k_proj\n","Replaced layer: layers.31.self_attn.v_proj\n","Replaced layer: layers.31.self_attn.o_proj\n","Replaced layer: layers.31.mlp.gate_proj\n","Replaced layer: layers.31.mlp.up_proj\n","Replaced layer: layers.31.mlp.down_proj\n","Original model size (parameters): 7504924672\n","Compressed model size (parameters): 609718272\n","Parameter compression rate: 91.88%\n","Original model file size: 33658.16 MB\n","Compressed model file size: 2417.21 MB\n","File size compression rate: 92.82%\n","Models saved to directories: original_model and compressed_model\n"]}],"source":["import os\n","import torch\n","import torch.nn as nn\n","from transformers import AutoTokenizer, AutoModel\n","from torch.nn import functional as F\n","\n","# Specify the model name and compression rank\n","MODEL_NAME = 'meta-llama/Meta-Llama-3-8B'  # Replace with your desired model name\n","COMPRESSION_RANK = 32  # Adjust this for more or less aggressive compression\n","\n","# Define LowRankLayer class for low-rank decomposition\n","class LowRankLayer(nn.Module):\n","    \"\"\"Given a linear layer, find low rank decomposition.\"\"\"\n","    def __init__(self, rank, full_rank_layer):\n","        super().__init__()\n","        self.rank = rank\n","\n","        # Perform SVD on the full-rank layer's weight matrix\n","        U, S, Vh = torch.linalg.svd(full_rank_layer.weight.float())\n","        S_diag = torch.diag(S)\n","        self.U = nn.Parameter(U[:, :self.rank].contiguous())\n","        self.S = nn.Parameter(S_diag[:self.rank, :self.rank].contiguous())\n","        self.Vh = nn.Parameter(Vh[:self.rank, :].contiguous())\n","\n","        # Handle the bias term if it exists\n","        if full_rank_layer.bias is not None:\n","            self.bias = nn.Parameter(full_rank_layer.bias.float().contiguous())\n","        else:\n","            self.bias = None\n","\n","    def forward(self, x):\n","        aprox_weight_matrix = self.U @ self.S @ self.Vh\n","        output = F.linear(x, aprox_weight_matrix, self.bias)\n","        return output\n","\n","# Function to replace linear layers with LowRankLayer\n","def replace_with_low_rank(model, rank):\n","    for name, module in model.named_modules():\n","        if isinstance(module, nn.Linear):\n","            # Create a LowRankLayer to replace the full-rank linear layer\n","            low_rank_layer = LowRankLayer(rank, module)\n","            parent_name, child_name = name.rsplit('.', 1)\n","            parent_module = model.get_submodule(parent_name)\n","            setattr(parent_module, child_name, low_rank_layer)\n","            print(f\"Replaced layer: {name}\")\n","    return model\n","\n","# Function to calculate the total number of parameters in the model\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","# Function to get the file size of a directory in bytes\n","def get_dir_size(dir_path):\n","    total_size = 0\n","    for dirpath, dirnames, filenames in os.walk(dir_path):\n","        for f in filenames:\n","            fp = os.path.join(dirpath, f)\n","            total_size += os.path.getsize(fp)\n","    return total_size\n","\n","# Load the tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModel.from_pretrained(MODEL_NAME)\n","\n","# Get initial size\n","original_size = count_parameters(model)\n","\n","# Save the original model to the directory\n","original_model_dir = \"original_model\"\n","tokenizer.save_pretrained(original_model_dir)\n","model.save_pretrained(original_model_dir)\n","\n","# Replace linear layers with low-rank approximations\n","model = replace_with_low_rank(model, COMPRESSION_RANK)\n","\n","# Get final size\n","compressed_size = count_parameters(model)\n","\n","# Save the compressed model to the directory\n","compressed_model_dir = \"compressed_model\"\n","tokenizer.save_pretrained(compressed_model_dir)\n","model.save_pretrained(compressed_model_dir)\n","\n","# Get the file sizes of the original and compressed models\n","original_file_size = get_dir_size(original_model_dir)\n","compressed_file_size = get_dir_size(compressed_model_dir)\n","\n","# Print sizes and compression rate\n","print(f\"Original model size (parameters): {original_size}\")\n","print(f\"Compressed model size (parameters): {compressed_size}\")\n","print(f\"Parameter compression rate: {(original_size - compressed_size) / original_size:.2%}\")\n","\n","print(f\"Original model file size: {original_file_size / (1024 ** 2):.2f} MB\")\n","print(f\"Compressed model file size: {compressed_file_size / (1024 ** 2):.2f} MB\")\n","print(f\"File size compression rate: {(original_file_size - compressed_file_size) / original_file_size:.2%}\")\n","\n","print(f\"Models saved to directories: {original_model_dir} and {compressed_model_dir}\")\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /home/azureuser/.cache/huggingface/token\n","Login successful\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a8fb8397ee334d35b2d271fd1ce8a15b","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/2.44G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Model pushed to Hugging Face at: https://huggingface.co/pavan01729/Compressed_LLama3_8b\n"]}],"source":["from huggingface_hub import HfApi, login\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","# Log in to Hugging Face\n","login(token=\"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\")\n","\n","# Define the model repository name\n","repo_name = \"pavan01729/Compressed_LLama3_8b\"  # Replace with your desired repo name\n","\n","# Push the model and tokenizer to the Hugging Face Hub\n","model.push_to_hub(repo_name, check_pr=True)\n","tokenizer.push_to_hub(repo_name, check_pr=True)\n","\n","print(f\"Model pushed to Hugging Face at: https://huggingface.co/{repo_name}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## LLama2-7b Original"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/azureuser/pavan/build/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"27176acbf3d641af9761f3124182ef60","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/home/azureuser/pavan/build/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7dbb8e76fd8448ccb08764dbfcc40a62","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00002.safetensors:   1%|          | 73.4M/9.98G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"707c4c61585b4cea87d9e2785f1da229","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e9b689c9ff7841a190e7d1c12958192e","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Replaced layer: layers.0.self_attn.q_proj\n","Replaced layer: layers.0.self_attn.k_proj\n","Replaced layer: layers.0.self_attn.v_proj\n","Replaced layer: layers.0.self_attn.o_proj\n","Replaced layer: layers.0.mlp.gate_proj\n","Replaced layer: layers.0.mlp.up_proj\n","Replaced layer: layers.0.mlp.down_proj\n","Replaced layer: layers.1.self_attn.q_proj\n","Replaced layer: layers.1.self_attn.k_proj\n","Replaced layer: layers.1.self_attn.v_proj\n","Replaced layer: layers.1.self_attn.o_proj\n","Replaced layer: layers.1.mlp.gate_proj\n","Replaced layer: layers.1.mlp.up_proj\n","Replaced layer: layers.1.mlp.down_proj\n","Replaced layer: layers.2.self_attn.q_proj\n","Replaced layer: layers.2.self_attn.k_proj\n","Replaced layer: layers.2.self_attn.v_proj\n","Replaced layer: layers.2.self_attn.o_proj\n","Replaced layer: layers.2.mlp.gate_proj\n","Replaced layer: layers.2.mlp.up_proj\n","Replaced layer: layers.2.mlp.down_proj\n","Replaced layer: layers.3.self_attn.q_proj\n","Replaced layer: layers.3.self_attn.k_proj\n","Replaced layer: layers.3.self_attn.v_proj\n","Replaced layer: layers.3.self_attn.o_proj\n","Replaced layer: layers.3.mlp.gate_proj\n","Replaced layer: layers.3.mlp.up_proj\n","Replaced layer: layers.3.mlp.down_proj\n","Replaced layer: layers.4.self_attn.q_proj\n","Replaced layer: layers.4.self_attn.k_proj\n","Replaced layer: layers.4.self_attn.v_proj\n","Replaced layer: layers.4.self_attn.o_proj\n","Replaced layer: layers.4.mlp.gate_proj\n","Replaced layer: layers.4.mlp.up_proj\n","Replaced layer: layers.4.mlp.down_proj\n","Replaced layer: layers.5.self_attn.q_proj\n","Replaced layer: layers.5.self_attn.k_proj\n","Replaced layer: layers.5.self_attn.v_proj\n","Replaced layer: layers.5.self_attn.o_proj\n","Replaced layer: layers.5.mlp.gate_proj\n","Replaced layer: layers.5.mlp.up_proj\n","Replaced layer: layers.5.mlp.down_proj\n","Replaced layer: layers.6.self_attn.q_proj\n","Replaced layer: layers.6.self_attn.k_proj\n","Replaced layer: layers.6.self_attn.v_proj\n","Replaced layer: layers.6.self_attn.o_proj\n","Replaced layer: layers.6.mlp.gate_proj\n","Replaced layer: layers.6.mlp.up_proj\n","Replaced layer: layers.6.mlp.down_proj\n","Replaced layer: layers.7.self_attn.q_proj\n","Replaced layer: layers.7.self_attn.k_proj\n","Replaced layer: layers.7.self_attn.v_proj\n","Replaced layer: layers.7.self_attn.o_proj\n","Replaced layer: layers.7.mlp.gate_proj\n","Replaced layer: layers.7.mlp.up_proj\n","Replaced layer: layers.7.mlp.down_proj\n","Replaced layer: layers.8.self_attn.q_proj\n","Replaced layer: layers.8.self_attn.k_proj\n","Replaced layer: layers.8.self_attn.v_proj\n","Replaced layer: layers.8.self_attn.o_proj\n","Replaced layer: layers.8.mlp.gate_proj\n","Replaced layer: layers.8.mlp.up_proj\n","Replaced layer: layers.8.mlp.down_proj\n","Replaced layer: layers.9.self_attn.q_proj\n","Replaced layer: layers.9.self_attn.k_proj\n","Replaced layer: layers.9.self_attn.v_proj\n","Replaced layer: layers.9.self_attn.o_proj\n","Replaced layer: layers.9.mlp.gate_proj\n","Replaced layer: layers.9.mlp.up_proj\n","Replaced layer: layers.9.mlp.down_proj\n","Replaced layer: layers.10.self_attn.q_proj\n","Replaced layer: layers.10.self_attn.k_proj\n","Replaced layer: layers.10.self_attn.v_proj\n","Replaced layer: layers.10.self_attn.o_proj\n","Replaced layer: layers.10.mlp.gate_proj\n","Replaced layer: layers.10.mlp.up_proj\n","Replaced layer: layers.10.mlp.down_proj\n","Replaced layer: layers.11.self_attn.q_proj\n","Replaced layer: layers.11.self_attn.k_proj\n","Replaced layer: layers.11.self_attn.v_proj\n","Replaced layer: layers.11.self_attn.o_proj\n","Replaced layer: layers.11.mlp.gate_proj\n","Replaced layer: layers.11.mlp.up_proj\n","Replaced layer: layers.11.mlp.down_proj\n","Replaced layer: layers.12.self_attn.q_proj\n","Replaced layer: layers.12.self_attn.k_proj\n","Replaced layer: layers.12.self_attn.v_proj\n","Replaced layer: layers.12.self_attn.o_proj\n","Replaced layer: layers.12.mlp.gate_proj\n","Replaced layer: layers.12.mlp.up_proj\n","Replaced layer: layers.12.mlp.down_proj\n","Replaced layer: layers.13.self_attn.q_proj\n","Replaced layer: layers.13.self_attn.k_proj\n","Replaced layer: layers.13.self_attn.v_proj\n","Replaced layer: layers.13.self_attn.o_proj\n","Replaced layer: layers.13.mlp.gate_proj\n","Replaced layer: layers.13.mlp.up_proj\n","Replaced layer: layers.13.mlp.down_proj\n","Replaced layer: layers.14.self_attn.q_proj\n","Replaced layer: layers.14.self_attn.k_proj\n","Replaced layer: layers.14.self_attn.v_proj\n","Replaced layer: layers.14.self_attn.o_proj\n","Replaced layer: layers.14.mlp.gate_proj\n","Replaced layer: layers.14.mlp.up_proj\n","Replaced layer: layers.14.mlp.down_proj\n","Replaced layer: layers.15.self_attn.q_proj\n","Replaced layer: layers.15.self_attn.k_proj\n","Replaced layer: layers.15.self_attn.v_proj\n","Replaced layer: layers.15.self_attn.o_proj\n","Replaced layer: layers.15.mlp.gate_proj\n","Replaced layer: layers.15.mlp.up_proj\n","Replaced layer: layers.15.mlp.down_proj\n","Replaced layer: layers.16.self_attn.q_proj\n","Replaced layer: layers.16.self_attn.k_proj\n","Replaced layer: layers.16.self_attn.v_proj\n","Replaced layer: layers.16.self_attn.o_proj\n","Replaced layer: layers.16.mlp.gate_proj\n","Replaced layer: layers.16.mlp.up_proj\n","Replaced layer: layers.16.mlp.down_proj\n","Replaced layer: layers.17.self_attn.q_proj\n","Replaced layer: layers.17.self_attn.k_proj\n","Replaced layer: layers.17.self_attn.v_proj\n","Replaced layer: layers.17.self_attn.o_proj\n","Replaced layer: layers.17.mlp.gate_proj\n","Replaced layer: layers.17.mlp.up_proj\n","Replaced layer: layers.17.mlp.down_proj\n","Replaced layer: layers.18.self_attn.q_proj\n","Replaced layer: layers.18.self_attn.k_proj\n","Replaced layer: layers.18.self_attn.v_proj\n","Replaced layer: layers.18.self_attn.o_proj\n","Replaced layer: layers.18.mlp.gate_proj\n","Replaced layer: layers.18.mlp.up_proj\n","Replaced layer: layers.18.mlp.down_proj\n","Replaced layer: layers.19.self_attn.q_proj\n","Replaced layer: layers.19.self_attn.k_proj\n","Replaced layer: layers.19.self_attn.v_proj\n","Replaced layer: layers.19.self_attn.o_proj\n","Replaced layer: layers.19.mlp.gate_proj\n","Replaced layer: layers.19.mlp.up_proj\n","Replaced layer: layers.19.mlp.down_proj\n","Replaced layer: layers.20.self_attn.q_proj\n","Replaced layer: layers.20.self_attn.k_proj\n","Replaced layer: layers.20.self_attn.v_proj\n","Replaced layer: layers.20.self_attn.o_proj\n","Replaced layer: layers.20.mlp.gate_proj\n","Replaced layer: layers.20.mlp.up_proj\n","Replaced layer: layers.20.mlp.down_proj\n","Replaced layer: layers.21.self_attn.q_proj\n","Replaced layer: layers.21.self_attn.k_proj\n","Replaced layer: layers.21.self_attn.v_proj\n","Replaced layer: layers.21.self_attn.o_proj\n","Replaced layer: layers.21.mlp.gate_proj\n","Replaced layer: layers.21.mlp.up_proj\n","Replaced layer: layers.21.mlp.down_proj\n","Replaced layer: layers.22.self_attn.q_proj\n","Replaced layer: layers.22.self_attn.k_proj\n","Replaced layer: layers.22.self_attn.v_proj\n","Replaced layer: layers.22.self_attn.o_proj\n","Replaced layer: layers.22.mlp.gate_proj\n","Replaced layer: layers.22.mlp.up_proj\n","Replaced layer: layers.22.mlp.down_proj\n","Replaced layer: layers.23.self_attn.q_proj\n","Replaced layer: layers.23.self_attn.k_proj\n","Replaced layer: layers.23.self_attn.v_proj\n","Replaced layer: layers.23.self_attn.o_proj\n","Replaced layer: layers.23.mlp.gate_proj\n","Replaced layer: layers.23.mlp.up_proj\n","Replaced layer: layers.23.mlp.down_proj\n","Replaced layer: layers.24.self_attn.q_proj\n","Replaced layer: layers.24.self_attn.k_proj\n","Replaced layer: layers.24.self_attn.v_proj\n","Replaced layer: layers.24.self_attn.o_proj\n","Replaced layer: layers.24.mlp.gate_proj\n","Replaced layer: layers.24.mlp.up_proj\n","Replaced layer: layers.24.mlp.down_proj\n","Replaced layer: layers.25.self_attn.q_proj\n","Replaced layer: layers.25.self_attn.k_proj\n","Replaced layer: layers.25.self_attn.v_proj\n","Replaced layer: layers.25.self_attn.o_proj\n","Replaced layer: layers.25.mlp.gate_proj\n","Replaced layer: layers.25.mlp.up_proj\n","Replaced layer: layers.25.mlp.down_proj\n","Replaced layer: layers.26.self_attn.q_proj\n","Replaced layer: layers.26.self_attn.k_proj\n","Replaced layer: layers.26.self_attn.v_proj\n","Replaced layer: layers.26.self_attn.o_proj\n","Replaced layer: layers.26.mlp.gate_proj\n","Replaced layer: layers.26.mlp.up_proj\n","Replaced layer: layers.26.mlp.down_proj\n","Replaced layer: layers.27.self_attn.q_proj\n","Replaced layer: layers.27.self_attn.k_proj\n","Replaced layer: layers.27.self_attn.v_proj\n","Replaced layer: layers.27.self_attn.o_proj\n","Replaced layer: layers.27.mlp.gate_proj\n","Replaced layer: layers.27.mlp.up_proj\n","Replaced layer: layers.27.mlp.down_proj\n","Replaced layer: layers.28.self_attn.q_proj\n","Replaced layer: layers.28.self_attn.k_proj\n","Replaced layer: layers.28.self_attn.v_proj\n","Replaced layer: layers.28.self_attn.o_proj\n","Replaced layer: layers.28.mlp.gate_proj\n","Replaced layer: layers.28.mlp.up_proj\n","Replaced layer: layers.28.mlp.down_proj\n","Replaced layer: layers.29.self_attn.q_proj\n","Replaced layer: layers.29.self_attn.k_proj\n","Replaced layer: layers.29.self_attn.v_proj\n","Replaced layer: layers.29.self_attn.o_proj\n","Replaced layer: layers.29.mlp.gate_proj\n","Replaced layer: layers.29.mlp.up_proj\n","Replaced layer: layers.29.mlp.down_proj\n","Replaced layer: layers.30.self_attn.q_proj\n","Replaced layer: layers.30.self_attn.k_proj\n","Replaced layer: layers.30.self_attn.v_proj\n","Replaced layer: layers.30.self_attn.o_proj\n","Replaced layer: layers.30.mlp.gate_proj\n","Replaced layer: layers.30.mlp.up_proj\n","Replaced layer: layers.30.mlp.down_proj\n","Replaced layer: layers.31.self_attn.q_proj\n","Replaced layer: layers.31.self_attn.k_proj\n","Replaced layer: layers.31.self_attn.v_proj\n","Replaced layer: layers.31.self_attn.o_proj\n","Replaced layer: layers.31.mlp.gate_proj\n","Replaced layer: layers.31.mlp.up_proj\n","Replaced layer: layers.31.mlp.down_proj\n","Original model size (parameters): 6607343616\n","Compressed model size (parameters): 454823936\n","Parameter compression rate: 93.12%\n","Original model file size: 25207.39 MB\n","Compressed model file size: 1819.39 MB\n","File size compression rate: 92.78%\n","Models saved to directories: original_model and compressed_model\n"]}],"source":["import os\n","import torch\n","import torch.nn as nn\n","from transformers import AutoTokenizer, AutoModel\n","from torch.nn import functional as F\n","\n","# Specify the model name and compression rank\n","MODEL_NAME = 'meta-llama/Llama-2-7b-chat-hf'  # Replace with your desired model name\n","COMPRESSION_RANK = 128  # Adjust this for more or less aggressive compression\n","\n","# Define LowRankLayer class for low-rank decomposition\n","class LowRankLayer(nn.Module):\n","    \"\"\"Given a linear layer, find low rank decomposition.\"\"\"\n","    def __init__(self, rank, full_rank_layer):\n","        super().__init__()\n","        self.rank = rank\n","\n","        # Perform SVD on the full-rank layer's weight matrix\n","        U, S, Vh = torch.linalg.svd(full_rank_layer.weight.float())\n","        S_diag = torch.diag(S)\n","        self.U = nn.Parameter(U[:, :self.rank].contiguous())\n","        self.S = nn.Parameter(S_diag[:self.rank, :self.rank].contiguous())\n","        self.Vh = nn.Parameter(Vh[:self.rank, :].contiguous())\n","\n","        # Handle the bias term if it exists\n","        if full_rank_layer.bias is not None:\n","            self.bias = nn.Parameter(full_rank_layer.bias.float().contiguous())\n","        else:\n","            self.bias = None\n","\n","    def forward(self, x):\n","        aprox_weight_matrix = self.U @ self.S @ self.Vh\n","        output = F.linear(x, aprox_weight_matrix, self.bias)\n","        return output\n","\n","# Function to replace linear layers with LowRankLayer\n","def replace_with_low_rank(model, rank):\n","    for name, module in model.named_modules():\n","        if isinstance(module, nn.Linear):\n","            # Create a LowRankLayer to replace the full-rank linear layer\n","            low_rank_layer = LowRankLayer(rank, module)\n","            parent_name, child_name = name.rsplit('.', 1)\n","            parent_module = model.get_submodule(parent_name)\n","            setattr(parent_module, child_name, low_rank_layer)\n","            print(f\"Replaced layer: {name}\")\n","    return model\n","\n","# Function to calculate the total number of parameters in the model\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","# Function to get the file size of a directory in bytes\n","def get_dir_size(dir_path):\n","    total_size = 0\n","    for dirpath, dirnames, filenames in os.walk(dir_path):\n","        for f in filenames:\n","            fp = os.path.join(dirpath, f)\n","            total_size += os.path.getsize(fp)\n","    return total_size\n","\n","# Load the tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModel.from_pretrained(MODEL_NAME)\n","\n","# Get initial size\n","original_size = count_parameters(model)\n","\n","# Save the original model to the directory\n","original_model_dir = \"original_model\"\n","tokenizer.save_pretrained(original_model_dir)\n","model.save_pretrained(original_model_dir)\n","\n","# Replace linear layers with low-rank approximations\n","model = replace_with_low_rank(model, COMPRESSION_RANK)\n","\n","# Get final size\n","compressed_size = count_parameters(model)\n","\n","# Save the compressed model to the directory\n","compressed_model_dir = \"compressed_model\"\n","tokenizer.save_pretrained(compressed_model_dir)\n","model.save_pretrained(compressed_model_dir)\n","\n","# Get the file sizes of the original and compressed models\n","original_file_size = get_dir_size(original_model_dir)\n","compressed_file_size = get_dir_size(compressed_model_dir)\n","\n","# Print sizes and compression rate\n","print(f\"Original model size (parameters): {original_size}\")\n","print(f\"Compressed model size (parameters): {compressed_size}\")\n","print(f\"Parameter compression rate: {(original_size - compressed_size) / original_size:.2%}\")\n","\n","print(f\"Original model file size: {original_file_size / (1024 ** 2):.2f} MB\")\n","print(f\"Compressed model file size: {compressed_file_size / (1024 ** 2):.2f} MB\")\n","print(f\"File size compression rate: {(original_file_size - compressed_file_size) / original_file_size:.2%}\")\n","\n","print(f\"Models saved to directories: {original_model_dir} and {compressed_model_dir}\")\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /home/azureuser/.cache/huggingface/token\n","Login successful\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12ff18a85a204c2ba6dd25aeb7b7747c","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/1.82G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"51ca4023ce5f475c9b733daea4fcc291","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Model pushed to Hugging Face at: https://huggingface.co/pavan01729/Compressed_LLama2_7b\n"]}],"source":["from huggingface_hub import HfApi, login\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","# Log in to Hugging Face\n","login(token=\"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\")\n","\n","# Define the model repository name\n","repo_name = \"pavan01729/Compressed_LLama2_7b\"  # Replace with your desired repo name\n","\n","# Push the model and tokenizer to the Hugging Face Hub\n","model.push_to_hub(repo_name, check_pr=True)\n","tokenizer.push_to_hub(repo_name, check_pr=True)\n","\n","print(f\"Model pushed to Hugging Face at: https://huggingface.co/{repo_name}\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /home/azureuser/.cache/huggingface/token\n","Login successful\n"]}],"source":["from huggingface_hub import HfApi, login\n","\n","# Log in to Hugging Face\n","token = \"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\"  # Replace with your Hugging Face token\n","login(token)\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /home/azureuser/pavan/build/lib/python3.10/site-packages (4.31.0)\n","Collecting transformers\n","  Using cached transformers-4.42.3-py3-none-any.whl.metadata (43 kB)\n","Requirement already satisfied: filelock in /home/azureuser/pavan/build/lib/python3.10/site-packages (from transformers) (3.15.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/azureuser/pavan/build/lib/python3.10/site-packages (from transformers) (0.23.4)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /home/azureuser/pavan/build/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /home/azureuser/pavan/build/lib/python3.10/site-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /home/azureuser/pavan/build/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /home/azureuser/pavan/build/lib/python3.10/site-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /home/azureuser/pavan/build/lib/python3.10/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /home/azureuser/pavan/build/lib/python3.10/site-packages (from transformers) (0.4.3)\n","Collecting tokenizers<0.20,>=0.19 (from transformers)\n","  Using cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: tqdm>=4.27 in /home/azureuser/pavan/build/lib/python3.10/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /home/azureuser/pavan/build/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/azureuser/pavan/build/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/azureuser/pavan/build/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /home/azureuser/pavan/build/lib/python3.10/site-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /home/azureuser/pavan/build/lib/python3.10/site-packages (from requests->transformers) (2.2.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/azureuser/pavan/build/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n","Using cached transformers-4.42.3-py3-none-any.whl (9.3 MB)\n","Using cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","Installing collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.13.3\n","    Uninstalling tokenizers-0.13.3:\n","      Successfully uninstalled tokenizers-0.13.3\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.31.0\n","    Uninstalling transformers-4.31.0:\n","      Successfully uninstalled transformers-4.31.0\n","Successfully installed tokenizers-0.19.1 transformers-4.42.3\n","Error loading model or tokenizer: data did not match any variant of untagged enum PyPreTokenizerTypeWrapper at line 40 column 3\n","Original model size (parameters): 20890112\n","Compressed model size (parameters): 20890112\n","Parameter compression rate: 0.00%\n","Original model size (bytes): 79.80 MB\n","Compressed model size (bytes): 79.80 MB\n","File size compression rate: 0.00%\n","Compressed model saved to directory: compressed_model\n"]}],"source":["import torch\n","import torch.nn as nn\n","from transformers import AutoTokenizer, AutoModel\n","from torch.nn import functional as F\n","import tempfile\n","import os\n","\n","# Specify the model name and compression rank\n","MODEL_NAME = 'mistralai/Mistral-7B-Instruct-v0.2'  # Replace with your desired model name\n","COMPRESSION_RANK = 32  # Adjust this for more or less aggressive compression\n","\n","# Define LowRankLayer class for low-rank decomposition\n","class LowRankLayer(nn.Module):\n","    \"\"\"Given a linear layer, find low rank decomposition.\"\"\"\n","    def __init__(self, rank, full_rank_layer):\n","        super().__init__()\n","        self.rank = rank\n","\n","        # Perform SVD on the full-rank layer's weight matrix\n","        U, S, Vh = torch.linalg.svd(full_rank_layer.weight.float())\n","        S_diag = torch.diag(S)\n","        self.U = nn.Parameter(U[:, :self.rank].contiguous())\n","        self.S = nn.Parameter(S_diag[:self.rank, :self.rank].contiguous())\n","        self.Vh = nn.Parameter(Vh[:self.rank, :].contiguous())\n","\n","        # Handle the bias term if it exists\n","        if full_rank_layer.bias is not None:\n","            self.bias = nn.Parameter(full_rank_layer.bias.float().contiguous())\n","        else:\n","            self.bias = None\n","\n","    def forward(self, x):\n","        aprox_weight_matrix = self.U @ self.S @ self.Vh\n","        output = F.linear(x, aprox_weight_matrix, self.bias)\n","        return output\n","\n","# Function to replace linear layers with LowRankLayer\n","def replace_with_low_rank(model, rank):\n","    for name, module in model.named_modules():\n","        if isinstance(module, nn.Linear):\n","            # Create a LowRankLayer to replace the full-rank linear layer\n","            low_rank_layer = LowRankLayer(rank, module)\n","            parent_name, child_name = name.rsplit('.', 1)\n","            parent_module = model.get_submodule(parent_name)\n","            setattr(parent_module, child_name, low_rank_layer)\n","            print(f\"Replaced layer: {name}\")\n","    return model\n","\n","# Function to calculate the total number of parameters in the model\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","# Function to get the size of a model saved to a temporary file\n","def get_model_size_in_bytes(model):\n","    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n","        torch.save(model.state_dict(), tmp_file.name)\n","        tmp_file.seek(0, os.SEEK_END)\n","        size = tmp_file.tell()\n","    os.remove(tmp_file.name)  # Delete the temporary file immediately after getting its size\n","    return size\n","\n","# Load the tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModel.from_pretrained(MODEL_NAME)\n","\n","# Get initial parameter count and file size\n","original_size_params = count_parameters(model)\n","original_size_bytes = get_model_size_in_bytes(model)\n","\n","# Replace linear layers with low-rank approximations\n","model = replace_with_low_rank(model, COMPRESSION_RANK)\n","\n","# Get final parameter count and file size\n","compressed_size_params = count_parameters(model)\n","compressed_size_bytes = get_model_size_in_bytes(model)\n","\n","# Print sizes and compression rates\n","print(f\"Original model size (parameters): {original_size_params}\")\n","print(f\"Compressed model size (parameters): {compressed_size_params}\")\n","print(f\"Parameter compression rate: {(original_size_params - compressed_size_params) / original_size_params:.2%}\")\n","\n","print(f\"Original model size (bytes): {original_size_bytes / (1024 ** 2):.2f} MB\")\n","print(f\"Compressed model size (bytes): {compressed_size_bytes / (1024 ** 2):.2f} MB\")\n","print(f\"File size compression rate: {(original_size_bytes - compressed_size_bytes) / original_size_bytes:.2%}\")\n","\n","# Save the tokenizer and compressed model to the directory\n","model_dir = \"compressed_model\"\n","tokenizer.save_pretrained(model_dir)\n","model.save_pretrained(model_dir)\n","\n","print(f\"Compressed model saved to directory: {model_dir}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0069f92422a64a5d85d7637cd35758c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0413433de3cf453dae054bd9f710f586":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0426fe4d9fb649b29bb5a4052aebf30c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07473ba8774b4fb6b1ba541769d7b8bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1cab7a0b22094a098519ad7632b6f097":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f60bb96e4f14cf98267447026fbe636":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1432527c5674691b82cceeb36fe683f","placeholder":"","style":"IPY_MODEL_ad7b0edc469440019eefe55621bb88b5","value":"tokenizer.json:100%"}},"1fb329b7ba344edab6939ffc0502516f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"203bd42827d144e7bfdd52b23615141a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d1fb72fcde3e4dc886c94b7fa9a10107","IPY_MODEL_4eca8d10bf1f478aacda60d96589961f","IPY_MODEL_c46affb99ccd475c9950a5b17cb50d7e"],"layout":"IPY_MODEL_1cab7a0b22094a098519ad7632b6f097"}},"24394d99d942436d99d7275b9f3308b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1f60bb96e4f14cf98267447026fbe636","IPY_MODEL_e753ffe8e2e442c0b785f3c6cdd20dfe","IPY_MODEL_40e4c10079844ad1ad192c558867468c"],"layout":"IPY_MODEL_55ba1263d06f4b5fb8d92588f84d6d9f"}},"2517d13755b74a1d8edf145627ba20d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2822d6f2dbfa427993e462e799ae2800":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2aef9145fb264d07ab79d9f64c01e3e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e53ba1af1bd46f3af935851e3330d14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fb329b7ba344edab6939ffc0502516f","placeholder":"","style":"IPY_MODEL_68902abaeb174ec2ad798589aa3b3cd2","value":"merges.txt:100%"}},"3d6866f0013e4790a8215d01789362c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3da7e881c8fa45f8b79c2546fc0c6162":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40e0d6b64a0144b9bc24eeeb180325e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40e4c10079844ad1ad192c558867468c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4dd4e10b536941a2abfa4f632104863b","placeholder":"","style":"IPY_MODEL_9c1d40ef87b6408aa44e7628a8c655da","value":"2.11M/2.11M[00:00&lt;00:00,2.51MB/s]"}},"40fc697256a347cf94a462fc06b4b83d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3da7e881c8fa45f8b79c2546fc0c6162","max":237,"min":0,"orientation":"horizontal","style":"IPY_MODEL_78ba2947a2874a36be79c95d7f3894f2","value":237}},"46af57e9bf484b368e269f3fa7b597df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"488f707db81548cda349ddd990334998":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cb0c2b5aa4e4b599fb74404fbe57a3f","placeholder":"","style":"IPY_MODEL_dec3c162337c4a1a905237fa1e01fa45","value":"added_tokens.json:100%"}},"4cb0c2b5aa4e4b599fb74404fbe57a3f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dd4e10b536941a2abfa4f632104863b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4eca8d10bf1f478aacda60d96589961f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e123209fe8c45de8113457c6acc5f36","max":99,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b6783f42c4ae4a149a26f143d47a16f9","value":99}},"55ba1263d06f4b5fb8d92588f84d6d9f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55efc9ac6267403999345da8c2e766b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58d0c92542d54c839c74070a19ee2e09":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e8be4a6feaf47038b12959f4a2c23e7","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f25b06d8a9e1481f8ff50fe4b1eeddaf","value":456318}},"64ed74ffdbd74258862477d2ff5cb53a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65d4801981624bd5a3bc20911c3540bc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68902abaeb174ec2ad798589aa3b3cd2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"694df95566db4e809a6c534e9bbfae8c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c99ef41becc5410ab1ad5bdc18ff888f","placeholder":"","style":"IPY_MODEL_0426fe4d9fb649b29bb5a4052aebf30c","value":"237/237[00:00&lt;00:00,8.07kB/s]"}},"69d80ef24d5148bcb067b318b2e96381":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bd5adf52c0aa4927b489ef9a64bece68","IPY_MODEL_902f4c7ef4764ecc8a54b99c905d08f5","IPY_MODEL_e5b695d8721241da9638bde4e4eaa668"],"layout":"IPY_MODEL_c27738fccd734d4f94efd58dcc6c46cb"}},"731c58a04c4445fc99688de7497f82a6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76d50c0508f145ecabc124e3f016b27c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3c9969838bb4078b5aad7ecacb8c19f","max":1080,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2517d13755b74a1d8edf145627ba20d0","value":1080}},"78ba2947a2874a36be79c95d7f3894f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d10b2289f6c496b8b594c94e4ce8564":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e8be4a6feaf47038b12959f4a2c23e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"902f4c7ef4764ecc8a54b99c905d08f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_46af57e9bf484b368e269f3fa7b597df","max":798156,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cd001dc3bd554e5ea2c8ebbfe22ea279","value":798156}},"93c9b8892beb4a258c4697cd040750e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96a0a280d76b4924849980c3ddb0b4a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c1d40ef87b6408aa44e7628a8c655da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e123209fe8c45de8113457c6acc5f36":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9edcac24ac29420cb905150175e2791c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1432527c5674691b82cceeb36fe683f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad7b0edc469440019eefe55621bb88b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2f07ed0f4bb4a8895e63364c2930379":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_731c58a04c4445fc99688de7497f82a6","placeholder":"","style":"IPY_MODEL_0413433de3cf453dae054bd9f710f586","value":"tokenizer_config.json:100%"}},"b3c9969838bb4078b5aad7ecacb8c19f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6783f42c4ae4a149a26f143d47a16f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b715f7d97211413c94951f0400afdb2a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba5b19e74e6948b2b2a57336feb3ebc0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_488f707db81548cda349ddd990334998","IPY_MODEL_76d50c0508f145ecabc124e3f016b27c","IPY_MODEL_e664c1df58644b24a1530d0cd1cd63f1"],"layout":"IPY_MODEL_2822d6f2dbfa427993e462e799ae2800"}},"bd5adf52c0aa4927b489ef9a64bece68":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d10b2289f6c496b8b594c94e4ce8564","placeholder":"","style":"IPY_MODEL_f6cfcec8913a46dba7fa42bc5b84269b","value":"vocab.json:100%"}},"c27738fccd734d4f94efd58dcc6c46cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c46affb99ccd475c9950a5b17cb50d7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93c9b8892beb4a258c4697cd040750e7","placeholder":"","style":"IPY_MODEL_3d6866f0013e4790a8215d01789362c6","value":"99.0/99.0[00:00&lt;00:00,6.99kB/s]"}},"c6374f3b729342e0a9636cce8d636d4a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_40e0d6b64a0144b9bc24eeeb180325e1","placeholder":"","style":"IPY_MODEL_96a0a280d76b4924849980c3ddb0b4a8","value":"456k/456k[00:00&lt;00:00,891kB/s]"}},"c7653971d4794207881a808997fdd548":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c99ef41becc5410ab1ad5bdc18ff888f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9ec3900306c4920b5f5a25ddbcb68ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd001dc3bd554e5ea2c8ebbfe22ea279":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d1fb72fcde3e4dc886c94b7fa9a10107":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2aef9145fb264d07ab79d9f64c01e3e1","placeholder":"","style":"IPY_MODEL_55efc9ac6267403999345da8c2e766b5","value":"special_tokens_map.json:100%"}},"dce9ec1b68cf49aa9088341a52d258fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2e53ba1af1bd46f3af935851e3330d14","IPY_MODEL_58d0c92542d54c839c74070a19ee2e09","IPY_MODEL_c6374f3b729342e0a9636cce8d636d4a"],"layout":"IPY_MODEL_b715f7d97211413c94951f0400afdb2a"}},"dec3c162337c4a1a905237fa1e01fa45":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e542341aec134fc3be4ade3a6dc66dde":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b2f07ed0f4bb4a8895e63364c2930379","IPY_MODEL_40fc697256a347cf94a462fc06b4b83d","IPY_MODEL_694df95566db4e809a6c534e9bbfae8c"],"layout":"IPY_MODEL_64ed74ffdbd74258862477d2ff5cb53a"}},"e5b695d8721241da9638bde4e4eaa668":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0069f92422a64a5d85d7637cd35758c7","placeholder":"","style":"IPY_MODEL_c9ec3900306c4920b5f5a25ddbcb68ba","value":"798k/798k[00:00&lt;00:00,4.55MB/s]"}},"e664c1df58644b24a1530d0cd1cd63f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9edcac24ac29420cb905150175e2791c","placeholder":"","style":"IPY_MODEL_c7653971d4794207881a808997fdd548","value":"1.08k/1.08k[00:00&lt;00:00,76.1kB/s]"}},"e753ffe8e2e442c0b785f3c6cdd20dfe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_65d4801981624bd5a3bc20911c3540bc","max":2114924,"min":0,"orientation":"horizontal","style":"IPY_MODEL_07473ba8774b4fb6b1ba541769d7b8bc","value":2114924}},"f25b06d8a9e1481f8ff50fe4b1eeddaf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f6cfcec8913a46dba7fa42bc5b84269b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":4}
