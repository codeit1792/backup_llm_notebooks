{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5acdb953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Big Bang!\n",
      "\n",
      "The Big Bang is the scientific theory that explains the origin and evolution of our universe. It's a mind-blowing concept that has been extensively studied and confirmed by a vast amount of observational evidence.\n",
      "\n",
      "**What happened?**\n",
      "\n",
      "About 13.8 billion years ago, all matter in the universe was condensed into an infinitely hot and dense point called a singularity. This singularity expanded rapidly, and as it did, it cooled and particles began to form. These particles eventually came together to create atoms, and later, the first stars and galaxies.\n",
      "\n",
      "**The key features of the Big Bang:**\n",
      "\n",
      "1. **Expansion**: The universe began expanding from this incredibly hot and dense state.\n",
      "2. **Singularity**: The point at which all matter was condensed.\n",
      "3. **High temperatures**: Initial temperatures were so high that particles could not form, and energy was the dominant force.\n",
      "4. **Cooling**: As expansion continued, temperatures cooled, allowing particles to form and eventually atoms, stars, and galaxies.\n",
      "\n",
      "**The evidence for the Big Bang:**\n",
      "\n",
      "1. **Cosmic Microwave Background Radiation**: In the 1960s, scientists discovered a faint glow of microwave radiation that fills the entire universe. This is thought to be the residual heat from the early universe.\n",
      "2. **Abundance of Light Elements**: According to the Big Bang theory, certain light elements (hydrogen, helium, and lithium) should have formed in the first few minutes after the universe began expanding. The abundance of these elements matches the predictions perfectly!\n",
      "3. **Large-scale Structure of the Universe**: Galaxies and galaxy clusters are distributed in a web-like pattern across the universe, which is consistent with the idea that the universe began as an extremely hot and dense state.\n",
      "4. **Redshift of Light from Distant Galaxies**: The light we observe from distant galaxies has been shifted towards the red end of the spectrum (redshift), indicating that those galaxies are moving away from us.\n",
      "\n",
      "**The Big Bang: A summary**\n",
      "\n",
      "In a nutshell, the Big Bang theory suggests that our universe began as an infinitely hot and dense point, expanded rapidly, and cooled over time. This led to the formation of particles, atoms, stars, and eventually galaxies like our own Milky Way. The evidence supporting this theory is overwhelming, making it one of the most well-established theories in modern astrophysics!\n",
      "\n",
      "Would you like me to elaborate on any specific aspect of the Big Bang?\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms.ollama import Ollama\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "def main():\n",
    "    response = query_llama3()\n",
    "    print(response)\n",
    "\n",
    "def query_llama3():\n",
    "    # Define the context for this example\n",
    "    context_text = \"what is big bang\"\n",
    "    \n",
    "    # Format the prompt\n",
    "    prompt = PROMPT_TEMPLATE.format(context=context_text)\n",
    "\n",
    "    # Instantiate the Llama3 model\n",
    "    model = Ollama(model=\"llama3\")\n",
    "    \n",
    "    # Get the response from the model\n",
    "    response_text = model.invoke(prompt)\n",
    "    \n",
    "    return response_text\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd8e4641",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 65\u001b[0m\n\u001b[0;32m     63\u001b[0m pdf_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../QpiAI_data.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with your PDF file path\u001b[39;00m\n\u001b[0;32m     64\u001b[0m output_csv \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqa_dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# The output CSV file path\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_csv\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 47\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(pdf_path, output_csv)\u001b[0m\n\u001b[0;32m     44\u001b[0m pdf_text \u001b[38;5;241m=\u001b[39m extract_text_from_pdf(pdf_path)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Generate Q&A pairs from the extracted text\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m qa_pairs \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_qa_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Process the generated Q&A pairs\u001b[39;00m\n\u001b[0;32m     50\u001b[0m questions \u001b[38;5;241m=\u001b[39m [pair[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m qa_pairs]\n",
      "Cell \u001b[1;32mIn[7], line 40\u001b[0m, in \u001b[0;36mgenerate_qa_pairs\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     38\u001b[0m response \u001b[38;5;241m=\u001b[39m query_llama3(text)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Assuming the response is a JSON formatted string containing Q&A pairs\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m qa_pairs \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m qa_pairs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\detect\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\detect\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\detect\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "import json\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Generate Q&A pairs based on the following text:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Q&A pairs:\n",
    "\"\"\"\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def query_llama3(context_text):\n",
    "    # Format the prompt\n",
    "    prompt = PROMPT_TEMPLATE.format(context=context_text)\n",
    "\n",
    "    # Instantiate the Llama3 model\n",
    "    model = Ollama(model=\"llama3\")\n",
    "    \n",
    "    # Get the response from the model\n",
    "    response_text = model.invoke(prompt)\n",
    "    \n",
    "    return response_text\n",
    "\n",
    "def generate_qa_pairs(text):\n",
    "    response = query_llama3(text)\n",
    "    # Assuming the response is a JSON formatted string containing Q&A pairs\n",
    "    qa_pairs = json.loads(response)\n",
    "    return qa_pairs\n",
    "\n",
    "def main(pdf_path, output_csv):\n",
    "    pdf_text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Generate Q&A pairs from the extracted text\n",
    "    qa_pairs = generate_qa_pairs(pdf_text)\n",
    "    \n",
    "    # Process the generated Q&A pairs\n",
    "    questions = [pair['question'] for pair in qa_pairs]\n",
    "    answers = [pair['answer'] for pair in qa_pairs]\n",
    "    \n",
    "    # Create a DataFrame and save it as CSV\n",
    "    data = {\n",
    "        'question': questions,\n",
    "        'answer': answers\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Q&A pairs saved to {output_csv}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = '../QpiAI_data.pdf'  # Replace with your PDF file path\n",
    "    output_csv = 'qa_dataset.csv'  # The output CSV file path\n",
    "    main(pdf_path, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855dd37e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
