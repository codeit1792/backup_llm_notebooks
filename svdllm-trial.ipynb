{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/AIoT-MLSys-Lab/SVD-LLM.git","metadata":{"execution":{"iopub.status.busy":"2024-06-28T11:43:32.649025Z","iopub.execute_input":"2024-06-28T11:43:32.649479Z","iopub.status.idle":"2024-06-28T11:43:34.218446Z","shell.execute_reply.started":"2024-06-28T11:43:32.649453Z","shell.execute_reply":"2024-06-28T11:43:34.217368Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'SVD-LLM'...\nremote: Enumerating objects: 156, done.\u001b[K\nremote: Counting objects: 100% (156/156), done.\u001b[K\nremote: Compressing objects: 100% (97/97), done.\u001b[K\nremote: Total 156 (delta 80), reused 126 (delta 57), pack-reused 0\u001b[K\nReceiving objects: 100% (156/156), 712.50 KiB | 22.98 MiB/s, done.\nResolving deltas: 100% (80/80), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"pwd","metadata":{"execution":{"iopub.status.busy":"2024-06-28T11:43:34.220831Z","iopub.execute_input":"2024-06-28T11:43:34.221200Z","iopub.status.idle":"2024-06-28T11:43:34.228916Z","shell.execute_reply.started":"2024-06-28T11:43:34.221164Z","shell.execute_reply":"2024-06-28T11:43:34.227953Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}]},{"cell_type":"code","source":"cd /kaggle/working/SVD-LLM","metadata":{"execution":{"iopub.status.busy":"2024-06-28T12:06:19.075551Z","iopub.execute_input":"2024-06-28T12:06:19.076349Z","iopub.status.idle":"2024-06-28T12:06:19.082406Z","shell.execute_reply.started":"2024-06-28T12:06:19.076311Z","shell.execute_reply":"2024-06-28T12:06:19.081570Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"/kaggle/working/SVD-LLM\n","output_type":"stream"}]},{"cell_type":"code","source":"# !bash compress_llama.sh","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-06-28T11:43:34.243678Z","iopub.execute_input":"2024-06-28T11:43:34.244010Z","iopub.status.idle":"2024-06-28T11:43:34.250241Z","shell.execute_reply.started":"2024-06-28T11:43:34.243971Z","shell.execute_reply":"2024-06-28T11:43:34.249440Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# !pip install -r requirements.txt\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-06-28T11:43:34.251376Z","iopub.execute_input":"2024-06-28T11:43:34.251730Z","iopub.status.idle":"2024-06-28T11:43:34.260231Z","shell.execute_reply.started":"2024-06-28T11:43:34.251700Z","shell.execute_reply":"2024-06-28T11:43:34.259410Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# !pip install numpy==1.17.0\n!pip install sentencepiece\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-06-28T11:43:34.261429Z","iopub.execute_input":"2024-06-28T11:43:34.261693Z","iopub.status.idle":"2024-06-28T11:43:47.858602Z","shell.execute_reply.started":"2024-06-28T11:43:34.261671Z","shell.execute_reply":"2024-06-28T11:43:47.857546Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!python SVDLLM.py \\\n--step 1 \\\n--ratio 0.1 \\\n--model gpt2 \\\n--whitening_nsamples 1000 \\\n--dataset wikitext-2 \\\n--seed 42 \\\n--model_seq_len 512 \\\n--save_path ./whitening_info\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-06-28T12:28:17.614027Z","iopub.execute_input":"2024-06-28T12:28:17.614307Z","iopub.status.idle":"2024-06-28T12:28:18.698648Z","shell.execute_reply.started":"2024-06-28T12:28:17.614281Z","shell.execute_reply":"2024-06-28T12:28:18.697445Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"python: can't open file '/kaggle/working/SVDLLM.py': [Errno 2] No such file or directory\n","output_type":"stream"}]},{"cell_type":"code","source":"# Step 1: Install Specific Versions of Dependencies\n# !pip uninstall -y numpy\n# !pip install numpy==1.17.0\n# !pip install transformers==4.35.2 torch==1.12.1 sentencepiece\n\n# Step 2: Clone the SVD-LLM Repository\n!git clone https://github.com/AIoT-MLSys-Lab/SVD-LLM.git\n%cd SVD-LLM\n\n# Step 3: Update model_utils.py to handle tokenizers correctly\nwith open(\"utils/model_utils.py\", \"r\") as file:\n    lines = file.readlines()\n\nwith open(\"utils/model_utils.py\", \"w\") as file:\n    for line in lines:\n        if \"def get_model_from_huggingface\" in line:\n            file.write(line)\n            file.write(\"\"\"\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, GPT2Tokenizer, LlamaTokenizer\n\ndef get_model_from_huggingface(model_id: str):\n    model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cpu\", trust_remote_code=True)\n    if \"llama\" in model_id.lower():\n        tokenizer = LlamaTokenizer.from_pretrained(model_id, device_map=\"cpu\", trust_remote_code=True)\n    else:\n        tokenizer = AutoTokenizer.from_pretrained(model_id, device_map=\"cpu\", trust_remote_code=True)\n    return model, tokenizer\n            \"\"\")\n        else:\n            file.write(line)\n\n# Step 4: Run the SVD-LLM Script with the Provided Parameters\n!python SVDLLM.py --step 1 --ratio 0.1 --model gpt2 --whitening_nsamples 1000 --dataset wikitext-2 --seed 42 --model_seq_len 512 --save_path ./whitening_info\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-06-28T12:28:18.700906Z","iopub.execute_input":"2024-06-28T12:28:18.701459Z","iopub.status.idle":"2024-06-28T12:28:34.184248Z","shell.execute_reply.started":"2024-06-28T12:28:18.701423Z","shell.execute_reply":"2024-06-28T12:28:34.183319Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'SVD-LLM'...\nremote: Enumerating objects: 156, done.\u001b[K\nremote: Counting objects: 100% (156/156), done.\u001b[K\nremote: Compressing objects: 100% (97/97), done.\u001b[K\nremote: Total 156 (delta 80), reused 126 (delta 57), pack-reused 0\u001b[K\nReceiving objects: 100% (156/156), 712.50 KiB | 5.94 MiB/s, done.\nResolving deltas: 100% (80/80), done.\n/kaggle/working/SVD-LLM\nTraceback (most recent call last):\n  File \"/kaggle/working/SVD-LLM/SVDLLM.py\", line 14, in <module>\n    from utils.model_utils import *\n  File \"/kaggle/working/SVD-LLM/utils/model_utils.py\", line 16\n    from transformers import AutoModelForCausalLM, AutoTokenizer, GPT2Tokenizer, LlamaTokenizer\n    ^\nIndentationError: expected an indented block after function definition on line 14\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Step 1: Install Specific Versions of Dependencies\n# !pip install transformers==4.35.2 torch==1.12.1 sentencepiece\n\n# Step 2: Clone the SVD-LLM Repository\n!git clone https://github.com/AIoT-MLSys-Lab/SVD-LLM.git\n%cd SVD-LLM\n\n# Step 3: Update model_utils.py to handle tokenizers correctly\nwith open(\"utils/model_utils.py\", \"r\") as file:\n    lines = file.readlines()\n\nwith open(\"utils/model_utils.py\", \"w\") as file:\n    for line in lines:\n        if \"def get_model_from_huggingface\" in line:\n            file.write(line)\n            file.write(\"\"\"\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, GPT2Tokenizer, LlamaTokenizer\n\ndef get_model_from_huggingface(model_id: str):\n    model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cpu\", trust_remote_code=True)\n    if \"llama\" in model_id.lower():\n        tokenizer = LlamaTokenizer.from_pretrained(model_id, device_map=\"cpu\", trust_remote_code=True)\n    else:\n        tokenizer = AutoTokenizer.from_pretrained(model_id, device_map=\"cpu\", trust_remote_code=True)\n    return model, tokenizer\n            \"\"\")\n        else:\n            file.write(line)\n\n# Step 4: Run the SVD-LLM Script with the Provided Parameters\n!python SVDLLM.py --step 1 --ratio 0.1 --model gpt2 --whitening_nsamples 1000 --dataset wikitext-2 --seed 42 --model_seq_len 512 --save_path ./whitening_info\n","metadata":{"execution":{"iopub.status.busy":"2024-06-28T12:28:34.185644Z","iopub.execute_input":"2024-06-28T12:28:34.185967Z","iopub.status.idle":"2024-06-28T12:28:36.743917Z","shell.execute_reply.started":"2024-06-28T12:28:34.185935Z","shell.execute_reply":"2024-06-28T12:28:36.742316Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Cloning into 'SVD-LLM'...\nremote: Enumerating objects: 156, done.\u001b[K\nremote: Counting objects: 100% (156/156), done.\u001b[K\nremote: Compressing objects: 100% (97/97), done.\u001b[K\nremote: Total 156 (delta 80), reused 126 (delta 57), pack-reused 0\u001b[K\nReceiving objects: 100% (156/156), 712.50 KiB | 5.89 MiB/s, done.\nResolving deltas: 100% (80/80), done.\n/kaggle/working/SVD-LLM/SVD-LLM\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/utils/_process_posix.py:148\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 148\u001b[0m     child \u001b[38;5;241m=\u001b[39m \u001b[43mpexpect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-c\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Vanilla Pexpect\u001b[39;00m\n\u001b[1;32m    149\u001b[0m flush \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pexpect/pty_spawn.py:205\u001b[0m, in \u001b[0;36mspawn.__init__\u001b[0;34m(self, command, args, timeout, maxread, searchwindowsize, logfile, cwd, env, ignore_sighup, echo, preexec_fn, encoding, codec_errors, dimensions, use_poll)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_poll \u001b[38;5;241m=\u001b[39m use_poll\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pexpect/pty_spawn.py:303\u001b[0m, in \u001b[0;36mspawn._spawn\u001b[0;34m(self, command, args, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m [a \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m a\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding)\n\u001b[1;32m    301\u001b[0m                  \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs]\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mptyproc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spawnpty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mptyproc\u001b[38;5;241m.\u001b[39mpid\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pexpect/pty_spawn.py:315\u001b[0m, in \u001b[0;36mspawn._spawnpty\u001b[0;34m(self, args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Spawn a pty and return an instance of PtyProcess.'''\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mptyprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPtyProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ptyprocess/ptyprocess.py:315\u001b[0m, in \u001b[0;36mPtyProcess.spawn\u001b[0;34m(cls, argv, cwd, env, echo, preexec_fn, dimensions, pass_fds)\u001b[0m\n\u001b[1;32m    314\u001b[0m os\u001b[38;5;241m.\u001b[39mclose(exec_err_pipe_write)\n\u001b[0;32m--> 315\u001b[0m exec_err_data \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexec_err_pipe_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m os\u001b[38;5;241m.\u001b[39mclose(exec_err_pipe_read)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m             file\u001b[38;5;241m.\u001b[39mwrite(line)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Step 4: Run the SVD-LLM Script with the Provided Parameters\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpython SVDLLM.py --step 1 --ratio 0.1 --model gpt2 --whitening_nsamples 1000 --dataset wikitext-2 --seed 42 --model_seq_len 512 --save_path ./whitening_info\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/utils/_process_posix.py:164\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    159\u001b[0m         out_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# We need to send ^C to the process.  The ascii code for '^C' is 3\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# (the character is known as ETX for 'End of Text', see\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# curses.ascii.ETX).\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m     \u001b[43mchild\u001b[49m\u001b[38;5;241m.\u001b[39msendline(\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# Read and print any more output the program might produce on its\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# way out.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'child' referenced before assignment"],"ename":"UnboundLocalError","evalue":"local variable 'child' referenced before assignment","output_type":"error"}]},{"cell_type":"code","source":"torch.set_default_device('cuda')\nmodel = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True, torch_dtype=\"auto\")\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True, torch_dtype=\"auto\")\ninputs = tokenizer('''```python\ndef print_prime(n):\n   \"\"\"\n   Print all primes between 1 and n\n   \"\"\"''', return_tensors=\"pt\", return_attention_mask=False)\n\noutputs = model.generate(**inputs, max_length=200)\ntext = tokenizer.batch_decode(outputs)[0]\nprint(text)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T12:32:09.838885Z","iopub.execute_input":"2024-06-28T12:32:09.839669Z","iopub.status.idle":"2024-06-28T12:32:09.869378Z","shell.execute_reply.started":"2024-06-28T12:32:09.839626Z","shell.execute_reply":"2024-06-28T12:32:09.868199Z"},"trusted":true},"execution_count":4,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mset_default_device(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/phi-1_5\u001b[39m\u001b[38;5;124m\"\u001b[39m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, torch_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/phi-1_5\u001b[39m\u001b[38;5;124m\"\u001b[39m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, torch_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"],"ename":"NameError","evalue":"name 'torch' is not defined","output_type":"error"}]},{"cell_type":"code","source":"from transformers import LlamaTokenizer, LlamaForCausalLM\n\n# Load the tokenizer\ntokenizer = LlamaTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")\n\n# Load the model\nmodel = LlamaForCausalLM.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")\n\n# Example usage\ntext = \"Hello, how are you?\"\ninputs = tokenizer(text, return_tensors=\"pt\")\n\n# Generate text\noutput = model.generate(**inputs, max_length=50)\nprint(tokenizer.decode(output[0], skip_special_tokens=True))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-28T12:35:49.283535Z","iopub.execute_input":"2024-06-28T12:35:49.283921Z","iopub.status.idle":"2024-06-28T12:38:45.954760Z","shell.execute_reply.started":"2024-06-28T12:35:49.283892Z","shell.execute_reply":"2024-06-28T12:38:45.953676Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10bc8f1ebefc4530a44114392a6bfdd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"820b3b346b2f4b5b8458cd7cd87ee5da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bd0e16aaa4b46329724928bc34c5e6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"871c043bfa294eea913e659aa036387e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c5c7d7ee26c434099e4cde0cbd45cf7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6402a296506842f5bb739d2ae2c311f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"784adb0ac47542bfaa0d5b4d0dd56cf6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79cd8fd528a24d1a925b9e531548071d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c46577bccce46b69fee896f8679cd03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65765cd5f77348b08fdf9e47c03b279f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0074ae8666a44ea819aa7acb57a572e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59450b06755a4ffe8f80de508f944c0d"}},"metadata":{}},{"name":"stdout","text":"Hello, how are you? It's so nice to meet you! *hugs*\n\nI'm just an AI, I don't have feelings or emotions like humans do, but I'm here to help\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.decomposition import TruncatedSVD\nfrom transformers import LlamaTokenizer, LlamaForCausalLM\n\n# # Load the tokenizer\n# tokenizer = LlamaTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")\n\n# # Load the model\n# model = LlamaForCausalLM.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")\n\ndef compress_weights_svd(model, n_components=256):\n    \"\"\"\n    Compress model weights using SVD.\n    \n    Args:\n    model: The pre-trained model\n    n_components: Number of singular values and vectors to keep (compression factor)\n    \n    Returns:\n    The compressed model\n    \"\"\"\n    for name, param in model.named_parameters():\n        if 'weight' in name and param.dim() > 1:\n            # Convert weights to 2D matrix\n            weight_matrix = param.data.cpu().numpy()\n            original_shape = weight_matrix.shape\n\n            # Perform SVD\n            svd = TruncatedSVD(n_components=n_components)\n            U = svd.fit_transform(weight_matrix)\n            S = svd.singular_values_\n            V = svd.components_\n\n            # Reconstruct the weight matrix\n            compressed_weight = np.dot(U, np.dot(np.diag(S), V))\n\n            # Ensure the shape is preserved\n            if compressed_weight.shape != original_shape:\n                compressed_weight = compressed_weight.reshape(original_shape)\n\n            # Assign the compressed weight back to the model\n            param.data = torch.tensor(compressed_weight).to(param.device)\n    \n    return model\n\n# Compress model weights using SVD\ncompressed_model = compress_weights_svd(model)\n\n# Example usage with compressed model\ntext = \"Hello, how are you?\"\ninputs = tokenizer(text, return_tensors=\"pt\")\n\n# Generate text using the compressed model\noutput = compressed_model.generate(**inputs, max_length=50)\nprint(tokenizer.decode(output[0], skip_special_tokens=True))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-28T12:38:45.958676Z","iopub.execute_input":"2024-06-28T12:38:45.958996Z","iopub.status.idle":"2024-06-28T12:48:36.170668Z","shell.execute_reply.started":"2024-06-28T12:38:45.958968Z","shell.execute_reply":"2024-06-28T12:48:36.169691Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Hello, how are you?   textttexttarchivi    textt  textttextttextt textt   ,  in  nd textttextttextt     Хронологијаion textt   \n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.decomposition import TruncatedSVD\nfrom transformers import LlamaTokenizer, LlamaForCausalLM\n\n# Load the tokenizer\ntokenizer = LlamaTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")\n\n# Load the model\nmodel = LlamaForCausalLM.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")\n\ndef compress_weights_svd(model, compression_percentage=50):\n    \"\"\"\n    Compress model weights using SVD.\n    \n    Args:\n    model: The pre-trained model\n    compression_percentage: Percentage of compression (0-100)\n    \n    Returns:\n    The compressed model\n    \"\"\"\n    for name, param in model.named_parameters():\n        if 'weight' in name and param.dim() > 1:\n            # Convert weights to 2D matrix\n            weight_matrix = param.data.cpu().numpy()\n            original_shape = weight_matrix.shape\n            \n            # Calculate the number of components to keep based on the compression percentage\n            n_components = int(min(original_shape) * (compression_percentage / 100))\n\n            # Perform SVD\n            svd = TruncatedSVD(n_components=n_components)\n            U = svd.fit_transform(weight_matrix)\n            S = svd.singular_values_\n            V = svd.components_\n\n            # Reconstruct the weight matrix\n            compressed_weight = np.dot(U, np.dot(np.diag(S), V))\n\n            # Ensure the shape is preserved\n            if compressed_weight.shape != original_shape:\n                compressed_weight = compressed_weight.reshape(original_shape)\n\n            # Assign the compressed weight back to the model\n            param.data = torch.tensor(compressed_weight).to(param.device)\n    \n    return model\n\n# Compress model weights using SVD with a desired compression percentage\ncompression_percentage = 50  # Adjust this value to control the compression percentage\ncompressed_model = compress_weights_svd(model, compression_percentage=compression_percentage)\n\n# Example usage with compressed model\ntext = \"Hello, how are you?\"\ninputs = tokenizer(text, return_tensors=\"pt\")\n\n# Generate text using the compressed model\noutput = compressed_model.generate(**inputs, max_length=50)\nprint(tokenizer.decode(output[0], skip_special_tokens=True))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-28T12:48:36.172813Z","iopub.execute_input":"2024-06-28T12:48:36.173162Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fdb44f765a0406a813d4cb099bfca35"}},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.decomposition import TruncatedSVD\nfrom transformers import LlamaTokenizer, LlamaForCausalLM\n\n# Load the tokenizer\ntokenizer = LlamaTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")\n\n# Load the model\nmodel = LlamaForCausalLM.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")\n\ndef compress_weights_svd(model, compression_percentage=50):\n    \"\"\"\n    Compress model weights using SVD.\n    \n    Args:\n    model: The pre-trained model\n    compression_percentage: Percentage of compression (0-100)\n    \n    Returns:\n    The compressed model\n    \"\"\"\n    for name, param in model.named_parameters():\n        if 'weight' in name and param.dim() > 1:\n            print(f\"Processing {name}...\")\n            # Convert weights to 2D matrix\n            weight_matrix = param.data.cpu().numpy()\n            original_shape = weight_matrix.shape\n            print(f\"Original shape: {original_shape}\")\n            print(f\"Original weights (first 5 elements): {weight_matrix.flatten()[:5]}\")\n            \n            # Calculate the number of components to keep based on the compression percentage\n            n_components = int(min(original_shape) * (compression_percentage / 100))\n\n            # Perform SVD\n            svd = TruncatedSVD(n_components=n_components)\n            U = svd.fit_transform(weight_matrix)\n            S = svd.singular_values_\n            V = svd.components_\n\n            # Reconstruct the weight matrix\n            compressed_weight = np.dot(U, np.dot(np.diag(S), V))\n\n            # Ensure the shape is preserved\n            if compressed_weight.shape != original_shape:\n                compressed_weight = compressed_weight.reshape(original_shape)\n\n            print(f\"Compressed shape: {compressed_weight.shape}\")\n            print(f\"Compressed weights (first 5 elements): {compressed_weight.flatten()[:5]}\")\n\n            # Assign the compressed weight back to the model\n            param.data = torch.tensor(compressed_weight).to(param.device)\n    \n    return model\n\n# Compress model weights using SVD with a desired compression percentage\ncompression_percentage = 50  # Adjust this value to control the compression percentage\ncompressed_model = compress_weights_svd(model, compression_percentage=compression_percentage)\n\n# Example usage with compressed model\ntext = \"Hello, how are you?\"\ninputs = tokenizer(text, return_tensors=\"pt\")\n\n# Generate text using the compressed model\noutput = compressed_model.generate(**inputs, max_length=50)\nprint(tokenizer.decode(output[0], skip_special_tokens=True))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-28T12:54:27.995801Z","iopub.execute_input":"2024-06-28T12:54:27.996668Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39291748377f4bd883290ac68bb85e4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba16efc18d7e4a7d8356c3a6455d23cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85659d16ab9f4db1ba9e9f2dfbcdb82a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b75459a16a274d89a62387615e74013d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcf1798bdecf4e15b0db955f06db2aea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55a2f5121da54d9483b08425a40c9b48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54b4bc1316484deca2f2cb5cc0321d7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47a82e084e5349c1b5e8c548f64eb543"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ff82ee1ff2c4a7ebd52fe60bbf33ed8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19dd64b808e14f698c140d17238dce5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bafa70f68304f8580f602d21ccb6025"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5b32ee499614a73ae8f12feea569f42"}},"metadata":{}},{"name":"stdout","text":"Processing model.embed_tokens.weight...\nOriginal shape: (32000, 4096)\nOriginal weights (first 5 elements): [ 1.1920929e-06 -1.7881393e-06 -4.2915344e-06  7.9870224e-06\n  1.9073486e-06]\nCompressed shape: (32000, 4096)\nCompressed weights (first 5 elements): [ 1.5775637e-05  2.8524200e-06 -2.4456103e-05  1.6099531e-05\n  1.4919729e-05]\nProcessing model.layers.0.self_attn.q_proj.weight...\nOriginal shape: (4096, 4096)\nOriginal weights (first 5 elements): [-0.00595093 -0.0145874  -0.00209045  0.00101471 -0.00952148]\nCompressed shape: (4096, 4096)\nCompressed weights (first 5 elements): [-0.01655972 -0.01580367 -0.00385394  0.01881668 -0.05653121]\nProcessing model.layers.0.self_attn.k_proj.weight...\nOriginal shape: (4096, 4096)\nOriginal weights (first 5 elements): [-0.01550293  0.0078125  -0.00105286  0.00592041  0.00209045]\nCompressed shape: (4096, 4096)\nCompressed weights (first 5 elements): [-0.1767958   0.04266389 -0.00517249  0.08422428  0.11802262]\nProcessing model.layers.0.self_attn.v_proj.weight...\nOriginal shape: (4096, 4096)\nOriginal weights (first 5 elements): [-3.1471252e-05 -2.3345947e-03  2.6550293e-03  4.9438477e-03\n  4.2724609e-03]\nCompressed shape: (4096, 4096)\nCompressed weights (first 5 elements): [ 0.00609087 -0.00193305  0.00669414  0.01229828  0.00637435]\nProcessing model.layers.0.self_attn.o_proj.weight...\nOriginal shape: (4096, 4096)\nOriginal weights (first 5 elements): [ 8.8691711e-05 -2.3040771e-03  4.3945312e-03 -5.4931641e-03\n -4.1503906e-03]\nCompressed shape: (4096, 4096)\nCompressed weights (first 5 elements): [ 0.00048081 -0.00094941  0.00262951 -0.00162546  0.00128761]\nProcessing model.layers.0.mlp.gate_proj.weight...\nOriginal shape: (11008, 4096)\nOriginal weights (first 5 elements): [ 0.01733398  0.01721191  0.02868652 -0.01269531  0.02709961]\nCompressed shape: (11008, 4096)\nCompressed weights (first 5 elements): [-0.00606367  0.02982585  0.05520265 -0.00018085  0.11691888]\nProcessing model.layers.0.mlp.up_proj.weight...\nOriginal shape: (11008, 4096)\nOriginal weights (first 5 elements): [ 0.00112915 -0.0291748   0.01556396 -0.01312256 -0.03222656]\nCompressed shape: (11008, 4096)\nCompressed weights (first 5 elements): [-0.0613473  -0.06773594  0.04645843 -0.03773893 -0.09899729]\nProcessing model.layers.0.mlp.down_proj.weight...\nOriginal shape: (4096, 11008)\nOriginal weights (first 5 elements): [ 0.0050354  -0.01306152  0.00964355 -0.00878906  0.02099609]\nCompressed shape: (4096, 11008)\nCompressed weights (first 5 elements): [ 0.01890169 -0.04359653  0.02561654 -0.01107502  0.0072311 ]\nProcessing model.layers.1.self_attn.q_proj.weight...\nOriginal shape: (4096, 4096)\nOriginal weights (first 5 elements): [-0.0133667   0.00805664 -0.03857422  0.01055908  0.012146  ]\nCompressed shape: (4096, 4096)\nCompressed weights (first 5 elements): [ 0.04389532  0.03525204 -0.30259854  0.21382275  0.1939745 ]\nProcessing model.layers.1.self_attn.k_proj.weight...\nOriginal shape: (4096, 4096)\nOriginal weights (first 5 elements): [-0.02478027 -0.00338745  0.03881836 -0.01574707 -0.0145874 ]\nCompressed shape: (4096, 4096)\nCompressed weights (first 5 elements): [-0.13678443  0.06021295  0.20474274 -0.11098891 -0.0029587 ]\nProcessing model.layers.1.self_attn.v_proj.weight...\nOriginal shape: (4096, 4096)\nOriginal weights (first 5 elements): [ 0.00799561 -0.00799561 -0.00366211  0.00570679  0.00866699]\nCompressed shape: (4096, 4096)\nCompressed weights (first 5 elements): [ 0.00060512 -0.00466562  0.00064323  0.01228     0.01023318]\nProcessing model.layers.1.self_attn.o_proj.weight...\nOriginal shape: (4096, 4096)\nOriginal weights (first 5 elements): [ 0.00454712 -0.01867676  0.01385498 -0.00357056  0.0090332 ]\nCompressed shape: (4096, 4096)\nCompressed weights (first 5 elements): [ 0.00519808 -0.0182855   0.00822508 -0.00428753  0.00832284]\nProcessing model.layers.1.mlp.gate_proj.weight...\nOriginal shape: (11008, 4096)\nOriginal weights (first 5 elements): [ 0.02770996 -0.00909424  0.03710938 -0.00424194  0.0088501 ]\nCompressed shape: (11008, 4096)\nCompressed weights (first 5 elements): [ 0.10560973 -0.0030871   0.1275277  -0.01992578  0.04388674]\nProcessing model.layers.1.mlp.up_proj.weight...\nOriginal shape: (11008, 4096)\nOriginal weights (first 5 elements): [ 0.00151825  0.03515625 -0.01599121  0.02160645  0.00735474]\nCompressed shape: (11008, 4096)\nCompressed weights (first 5 elements): [-0.01338678  0.08294035 -0.05437226  0.04453519  0.00207427]\nProcessing model.layers.1.mlp.down_proj.weight...\nOriginal shape: (4096, 11008)\nOriginal weights (first 5 elements): [0.00836182 0.00946045 0.05371094 0.00689697 0.02075195]\nCompressed shape: (4096, 11008)\nCompressed weights (first 5 elements): [ 0.02321331  0.02839518  0.09661602 -0.00030689  0.03983198]\nProcessing model.layers.2.self_attn.q_proj.weight...\nOriginal shape: (4096, 4096)\nOriginal weights (first 5 elements): [-0.02502441 -0.00866699  0.0071106   0.01513672  0.01696777]\nCompressed shape: (4096, 4096)\nCompressed weights (first 5 elements): [-0.09522515 -0.00973161  0.02657683  0.02771008  0.09575106]\nProcessing model.layers.2.self_attn.k_proj.weight...\nOriginal shape: (4096, 4096)\nOriginal weights (first 5 elements): [-0.00234985  0.00982666 -0.00723267  0.01367188 -0.00439453]\nCompressed shape: (4096, 4096)\nCompressed weights (first 5 elements): [ 0.09278443  0.09103042 -0.07433508 -0.03446301 -0.09238584]\nProcessing model.layers.2.self_attn.v_proj.weight...\nOriginal shape: (4096, 4096)\nOriginal weights (first 5 elements): [-0.00506592  0.00043106  0.02185059 -0.00039864  0.00564575]\nCompressed shape: (4096, 4096)\nCompressed weights (first 5 elements): [ 0.00638523 -0.01178348  0.01895571  0.00314483 -0.00083735]\nProcessing model.layers.2.self_attn.o_proj.weight...\nOriginal shape: (4096, 4096)\nOriginal weights (first 5 elements): [ 0.00016975  0.01574707  0.00854492  0.01757812 -0.02416992]\nCompressed shape: (4096, 4096)\nCompressed weights (first 5 elements): [ 0.00079956  0.02551863  0.01517822  0.0200714  -0.03999839]\nProcessing model.layers.2.mlp.gate_proj.weight...\nOriginal shape: (11008, 4096)\nOriginal weights (first 5 elements): [ 0.0072937   0.02380371 -0.01159668  0.0078125  -0.00842285]\nCompressed shape: (11008, 4096)\nCompressed weights (first 5 elements): [ 0.05768962  0.06748276 -0.03774425  0.07503127 -0.0292689 ]\nProcessing model.layers.2.mlp.up_proj.weight...\nOriginal shape: (11008, 4096)\nOriginal weights (first 5 elements): [ 0.00227356 -0.00210571  0.01391602  0.01452637  0.00012302]\nCompressed shape: (11008, 4096)\nCompressed weights (first 5 elements): [-0.01894844 -0.0065292   0.01540329  0.02374905 -0.02461563]\nProcessing model.layers.2.mlp.down_proj.weight...\nOriginal shape: (4096, 11008)\nOriginal weights (first 5 elements): [ 0.00830078  0.0135498   0.03344727 -0.015625   -0.00610352]\nCompressed shape: (4096, 11008)\nCompressed weights (first 5 elements): [ 0.00101141  0.02214964  0.09512297 -0.07203436  0.01911242]\nProcessing model.layers.3.self_attn.q_proj.weight...\nOriginal shape: (4096, 4096)\nOriginal weights (first 5 elements): [ 0.00680542  0.01330566 -0.00030327 -0.01202393  0.02978516]\nCompressed shape: (4096, 4096)\nCompressed weights (first 5 elements): [-0.00853988  0.0880309  -0.0202151  -0.07238145  0.19592828]\nProcessing model.layers.3.self_attn.k_proj.weight...\nOriginal shape: (4096, 4096)\nOriginal weights (first 5 elements): [ 0.00927734 -0.00817871 -0.0057373  -0.02868652  0.0135498 ]\nCompressed shape: (4096, 4096)\nCompressed weights (first 5 elements): [ 0.00332541  0.00768228 -0.00705329 -0.0373743   0.06517223]\nProcessing model.layers.3.self_attn.v_proj.weight...\nOriginal shape: (4096, 4096)\nOriginal weights (first 5 elements): [-0.00107574  0.01049805 -0.00485229  0.00274658 -0.00695801]\nCompressed shape: (4096, 4096)\nCompressed weights (first 5 elements): [-0.00405512 -0.00532849 -0.0136075   0.00321547 -0.01106859]\nProcessing model.layers.3.self_attn.o_proj.weight...\nOriginal shape: (4096, 4096)\nOriginal weights (first 5 elements): [-0.0291748   0.00793457 -0.0168457  -0.00285339 -0.0045166 ]\nCompressed shape: (4096, 4096)\nCompressed weights (first 5 elements): [-0.0441204   0.01135159 -0.00891902  0.00524142 -0.01197018]\nProcessing model.layers.3.mlp.gate_proj.weight...\nOriginal shape: (11008, 4096)\nOriginal weights (first 5 elements): [-0.00442505 -0.01263428 -0.01855469 -0.01623535  0.00476074]\nCompressed shape: (11008, 4096)\nCompressed weights (first 5 elements): [ 0.0311162  -0.03555861 -0.0573074  -0.03054825  0.04425028]\nProcessing model.layers.3.mlp.up_proj.weight...\nOriginal shape: (11008, 4096)\nOriginal weights (first 5 elements): [-0.00933838  0.01391602  0.00656128  0.02563477 -0.00366211]\nCompressed shape: (11008, 4096)\nCompressed weights (first 5 elements): [ 0.01108363  0.02938022  0.01202772  0.06229251 -0.06571212]\nProcessing model.layers.3.mlp.down_proj.weight...\nOriginal shape: (4096, 11008)\nOriginal weights (first 5 elements): [-0.00128937 -0.00686646  0.0067749  -0.00354004 -0.02087402]\nCompressed shape: (4096, 11008)\nCompressed weights (first 5 elements): [ 0.00941735 -0.01201805  0.04116997 -0.01478187 -0.04379525]\nProcessing model.layers.4.self_attn.q_proj.weight...\nOriginal shape: (4096, 4096)\nOriginal weights (first 5 elements): [-0.01672363  0.00332642 -0.00192261 -0.00509644 -0.0018692 ]\nCompressed shape: (4096, 4096)\nCompressed weights (first 5 elements): [-0.04766895 -0.02023212 -0.00593341  0.02362524 -0.01800841]\nProcessing model.layers.4.self_attn.k_proj.weight...\nOriginal shape: (4096, 4096)\nOriginal weights (first 5 elements): [-0.00897217  0.01373291 -0.01275635  0.0072937   0.00866699]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}